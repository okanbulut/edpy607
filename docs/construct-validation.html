<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Construct Validation | EDPY 607 ‚Äì Measurement Theory II</title>
  <meta name="description" content="This document includes the course notes for EDPY 607 - Measurement Theory II." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Construct Validation | EDPY 607 ‚Äì Measurement Theory II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This document includes the course notes for EDPY 607 - Measurement Theory II." />
  <meta name="github-repo" content="okanbulut/edpy607" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Construct Validation | EDPY 607 ‚Äì Measurement Theory II" />
  
  <meta name="twitter:description" content="This document includes the course notes for EDPY 607 - Measurement Theory II." />
  



<meta name="date" content="2023-01-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="advanced-irt-applications.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EDPY 607 - Measurement Theory II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#course-content"><i class="fa fa-check"></i><b>1.1</b> Course Content</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#chapters"><i class="fa fa-check"></i><b>1.2</b> Chapters</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="construct-validation.html"><a href="construct-validation.html"><i class="fa fa-check"></i><b>2</b> Construct Validation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="construct-validation.html"><a href="construct-validation.html#factor-analytic-methods"><i class="fa fa-check"></i><b>2.1</b> Factor Analytic Methods</a>
<ul>
<li class="chapter" data-level="" data-path="construct-validation.html"><a href="construct-validation.html#example-1-synthetic-aperture-personality-assessment"><i class="fa fa-check"></i>Example 1: Synthetic Aperture Personality Assessment</a></li>
<li class="chapter" data-level="" data-path="construct-validation.html"><a href="construct-validation.html#example-2-financial-well-being-scale"><i class="fa fa-check"></i>Example 2: Financial Well-Being Scale</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="advanced-irt-applications.html"><a href="advanced-irt-applications.html"><i class="fa fa-check"></i><b>3</b> Advanced IRT Applications</a></li>
<li class="chapter" data-level="4" data-path="digital-testing-applications.html"><a href="digital-testing-applications.html"><i class="fa fa-check"></i><b>4</b> Digital Testing Applications</a></li>
<li class="chapter" data-level="5" data-path="other-topics-in-computational-psychometrics.html"><a href="other-topics-in-computational-psychometrics.html"><i class="fa fa-check"></i><b>5</b> Other Topics in Computational Psychometrics</a></li>
<li class="divider"></li>
<li><a href="https://okanbulut.github.io/edpy607/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EDPY 607 ‚Äì Measurement Theory II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="construct-validation" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> Construct Validation<a href="construct-validation.html#construct-validation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This chapter will focus on the evaluation of construct validity in educational and psychological instruments through factor analytic methods and psychometric network analysis.</p>
<div id="factor-analytic-methods" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Factor Analytic Methods<a href="construct-validation.html#factor-analytic-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we will use factor exploratory factor analysis (EFA), confirmatory factor analysis (CFA), and principal component analysis (PCA) to evaluate the dimensionality of educational and psychological instruments. In the examples, we will use the following packages:</p>
<table class=" lightable-paper lightable-striped" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:irt1">Table 2.1: </span>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Package
</th>
<th style="text-align:left;">
URL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
DataExplorer
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=DataExplorer" class="uri">http://CRAN.R-project.org/package=DataExplorer</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
ggcorrplot
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=ggcorrplot" class="uri">http://CRAN.R-project.org/package=ggcorrplot</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
psych
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=psych" class="uri">http://CRAN.R-project.org/package=psych</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
lavaan
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=lavaan" class="uri">http://CRAN.R-project.org/package=lavaan</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
semPlot
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=semPlot" class="uri">http://CRAN.R-project.org/package=semPlot</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
ggplot2
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=ggplot2" class="uri">http://CRAN.R-project.org/package=ggplot2</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
mirt
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=mirt" class="uri">http://CRAN.R-project.org/package=mirt</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
MASS
</td>
<td style="text-align:left;">
<a href="http://CRAN.R-project.org/package=MASS" class="uri">http://CRAN.R-project.org/package=MASS</a>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>We will install these packages using <code>install.packages()</code> and then activate them in our R session using <code>library()</code> :</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="construct-validation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the packages</span></span>
<span id="cb1-2"><a href="construct-validation.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">c</span>(<span class="st">&quot;DataExplorer&quot;</span>, <span class="st">&quot;ggcorrplot&quot;</span>, <span class="st">&quot;psych&quot;</span>, <span class="st">&quot;lavaan&quot;</span>, <span class="st">&quot;semPlot&quot;</span>, </span>
<span id="cb1-3"><a href="construct-validation.html#cb1-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;ggplot2&quot;</span>, <span class="st">&quot;mirt&quot;</span>, <span class="st">&quot;MASS&quot;</span>))</span>
<span id="cb1-4"><a href="construct-validation.html#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="construct-validation.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Activate the required packages</span></span>
<span id="cb1-6"><a href="construct-validation.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;DataExplorer&quot;</span>) <span class="co"># for data summarization</span></span>
<span id="cb1-7"><a href="construct-validation.html#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggcorrplot&quot;</span>) <span class="co"># for creating correlation plots</span></span>
<span id="cb1-8"><a href="construct-validation.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;psych&quot;</span>) <span class="co"># for exploratory factor analysis</span></span>
<span id="cb1-9"><a href="construct-validation.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;lavaan&quot;</span>) <span class="co"># for confirmatory factor analysis</span></span>
<span id="cb1-10"><a href="construct-validation.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;semPlot&quot;</span>) <span class="co"># for creating path diagrams</span></span>
<span id="cb1-11"><a href="construct-validation.html#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;ggplot2&quot;</span>) <span class="co"># for general visualization tasks</span></span>
<span id="cb1-12"><a href="construct-validation.html#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mirt&quot;</span>) <span class="co"># for simulating response data</span></span>
<span id="cb1-13"><a href="construct-validation.html#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;MASS&quot;</span>) <span class="co"># for simulating correlated multivariate data</span></span></code></pre></div>
<div id="example-1-synthetic-aperture-personality-assessment" class="section level3 unnumbered hasAnchor">
<h3>Example 1: Synthetic Aperture Personality Assessment<a href="construct-validation.html#example-1-synthetic-aperture-personality-assessment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the first example, we will use the Synthetic Aperture Personality Assessment (SAPA)‚Äìa web-based personality assessment project (<a href="https://www.sapa-project.org/" class="uri">https://www.sapa-project.org/</a>). The purpose of SAPA is to find patterns among the vast number of ways that people differ from one another in terms of their thoughts, feelings, interests, abilities, desires, values, and preferences <span class="citation">(<a href="#ref-condon2014" role="doc-biblioref">Condon &amp; Revelle, 2014</a>; <a href="#ref-revelle2010" role="doc-biblioref">Revelle et al., 2010</a>)</span>. In this example, we will use a subset of SAPA (16 items) sampled from the full instrument (80 items) to develop online measures of ability. These 16 items measure four subskills (i.e., verbal reasoning, letter series, matrix reasoning, and spatial rotations) as part of the general intelligence, also known as <em>g</em> factor. The ‚Äúsapa_data.csv‚Äù dataset is a data frame with 1525 individuals who responded to 16 multiple-choice items in SAPA. The original dataset is included in the <strong>psych</strong> package <span class="citation">(<a href="#ref-R-psych" role="doc-biblioref">Revelle, 2022</a>)</span>. The dataset can be downloaded from <a href="data_and_codes/sapa_data.csv"><strong>sapa_data.csv</strong></a>. In addition, the R codes for the analyses presented in this section are available in <a href="data_and_codes/example1.R"><strong>example1.R</strong></a>.</p>
<div id="exploratory-data-analysis" class="section level4 unnumbered hasAnchor">
<h4>Exploratory Data Analysis<a href="construct-validation.html#exploratory-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We will begin our analysis by conducting <a href="https://okanbulut.github.io/bigdata/eda.html">exploratory data analysis (EDA)</a>. As you may remember from the <a href="https://okanbulut.github.io/edpy507/ctt.html">CTT</a> section, we use EDA to check the quality of our data and identify potential problems (i.e., missing values) in the data. In this section, we will import <a href="data_and_codes/sapa_data.csv">sapa_data.csv</a> into R and review the variables in the dataset using descriptive statistics and visualizations.</p>
<p>First, we will import the data into R using the <code>read.csv()</code> function and save it as ‚Äúsapa‚Äù.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="construct-validation.html#cb2-1" aria-hidden="true" tabindex="-1"></a>sapa <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;sapa_data.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Using the <code>head()</code> function, we can now view the first 6 rows of the <code>sapa</code> dataset:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="construct-validation.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(sapa)</span></code></pre></div>
<pre><code>  reason.4 reason.16 reason.17 reason.19 letter.7 letter.33 letter.34 letter.58 matrix.45 matrix.46 matrix.47
1        0         0         0         0        0         1         0         0         0         0         0
2        0         0         1         0        1         0         1         0         0         0         0
3        0         1         1         0        1         0         0         0         1         1         0
4        1         0         0         0        0         0         1         0         0         0         0
5        0         1         1         0        0         1         0         0         1         1         0
6        1         1         1         1        1         1         1         1         1         1         1
  matrix.55 rotate.3 rotate.4 rotate.6 rotate.8
1         1        0        0        0        0
2         0        0        0        1        0
3         0        0        0        0        0
4         0        0        0        0        0
5         0        0        0        0        0
6         0        1        1        1        0</code></pre>
<p>The dataset consists of 1525 rows (i.e., examinees) and 16 variables (i.e., SAPA items). We can get more information on the dataset using the <code>introduce()</code> and <code>plot_intro()</code> functions from the <strong>DataExplorer</strong> package <span class="citation">(<a href="#ref-R-DataExplorer" role="doc-biblioref">Cui, 2020</a>)</span>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="construct-validation.html#cb5-1" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">introduce</span>(sapa)</span>
<span id="cb5-2"><a href="construct-validation.html#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="construct-validation.html#cb5-3" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">plot_intro</span>(sapa)</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
rows
</td>
<td style="text-align:right;">
1,525
</td>
</tr>
<tr>
<td style="text-align:left;">
columns
</td>
<td style="text-align:right;">
16
</td>
</tr>
<tr>
<td style="text-align:left;">
discrete_columns
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
continuous_columns
</td>
<td style="text-align:right;">
16
</td>
</tr>
<tr>
<td style="text-align:left;">
all_missing_columns
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
total_missing_values
</td>
<td style="text-align:right;">
25
</td>
</tr>
<tr>
<td style="text-align:left;">
complete_rows
</td>
<td style="text-align:right;">
1,523
</td>
</tr>
<tr>
<td style="text-align:left;">
total_observations
</td>
<td style="text-align:right;">
24,400
</td>
</tr>
<tr>
<td style="text-align:left;">
memory_usage
</td>
<td style="text-align:right;">
101,832
</td>
</tr>
</tbody>
</table>
<p><img src="edpy607_files/figure-html/cons6-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The plot above shows that all of the variables in the dataset are continuous. We also see that some of the variables have missing values but the proportion of missing data is very small (only 0.10%). To have a closer look at missing values, we can visualize the proportion of missingness for each variable using <code>plot_missing()</code> from <strong>DataExplorer</strong>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="construct-validation.html#cb6-1" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">plot_missing</span>(sapa)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons7-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>As we analyze the sapa dataset, we may start with the assumption that all SAPA items measure the same latent trait (general intelligence or <em>g</em>). However, given that the items come from different content areas (i.e., verbal reasoning, letter series, matrix reasoning, and spatial rotations), we must ensure that these items are sufficiently correlated with each other.</p>
<p>Since the SAPA items are dichotomously scored (i.e., 0: incorrect and 1: correct), we cannot use Pearson correlations, which could be obtained using the <code>cor()</code> function in R. Instead, we will compute the inter-item correlations among the SAPA items using the <code>tetrachoric()</code> function from <strong>psych</strong> and then extract ‚Äúrho‚Äù (i.e., the correlation matrix of the items).</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="construct-validation.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the correlation matrix</span></span>
<span id="cb7-2"><a href="construct-validation.html#cb7-2" aria-hidden="true" tabindex="-1"></a>cormat <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">tetrachoric</span>(<span class="at">x =</span> sapa)<span class="sc">$</span>rho</span>
<span id="cb7-3"><a href="construct-validation.html#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="construct-validation.html#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the correlation matrix</span></span>
<span id="cb7-5"><a href="construct-validation.html#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cormat)</span></code></pre></div>
<table class="table table-striped table-condensed" style="font-size: 11px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
reason.4
</th>
<th style="text-align:right;">
reason.16
</th>
<th style="text-align:right;">
reason.17
</th>
<th style="text-align:right;">
reason.19
</th>
<th style="text-align:right;">
letter.7
</th>
<th style="text-align:right;">
letter.33
</th>
<th style="text-align:right;">
letter.34
</th>
<th style="text-align:right;">
letter.58
</th>
<th style="text-align:right;">
matrix.45
</th>
<th style="text-align:right;">
matrix.46
</th>
<th style="text-align:right;">
matrix.47
</th>
<th style="text-align:right;">
matrix.55
</th>
<th style="text-align:right;">
rotate.3
</th>
<th style="text-align:right;">
rotate.4
</th>
<th style="text-align:right;">
rotate.6
</th>
<th style="text-align:right;">
rotate.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
reason.4
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.474
</td>
<td style="text-align:right;">
0.600
</td>
<td style="text-align:right;">
0.484
</td>
<td style="text-align:right;">
0.462
</td>
<td style="text-align:right;">
0.380
</td>
<td style="text-align:right;">
0.479
</td>
<td style="text-align:right;">
0.455
</td>
<td style="text-align:right;">
0.431
</td>
<td style="text-align:right;">
0.399
</td>
<td style="text-align:right;">
0.401
</td>
<td style="text-align:right;">
0.299
</td>
<td style="text-align:right;">
0.456
</td>
<td style="text-align:right;">
0.491
</td>
<td style="text-align:right;">
0.447
</td>
<td style="text-align:right;">
0.436
</td>
</tr>
<tr>
<td style="text-align:left;">
reason.16
</td>
<td style="text-align:right;">
0.474
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.536
</td>
<td style="text-align:right;">
0.458
</td>
<td style="text-align:right;">
0.471
</td>
<td style="text-align:right;">
0.374
</td>
<td style="text-align:right;">
0.449
</td>
<td style="text-align:right;">
0.380
</td>
<td style="text-align:right;">
0.351
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.421
</td>
<td style="text-align:right;">
0.314
</td>
<td style="text-align:right;">
0.327
</td>
<td style="text-align:right;">
0.443
</td>
<td style="text-align:right;">
0.408
</td>
<td style="text-align:right;">
0.364
</td>
</tr>
<tr>
<td style="text-align:left;">
reason.17
</td>
<td style="text-align:right;">
0.600
</td>
<td style="text-align:right;">
0.536
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.550
</td>
<td style="text-align:right;">
0.473
</td>
<td style="text-align:right;">
0.440
</td>
<td style="text-align:right;">
0.473
</td>
<td style="text-align:right;">
0.480
</td>
<td style="text-align:right;">
0.358
</td>
<td style="text-align:right;">
0.392
</td>
<td style="text-align:right;">
0.466
</td>
<td style="text-align:right;">
0.316
</td>
<td style="text-align:right;">
0.386
</td>
<td style="text-align:right;">
0.427
</td>
<td style="text-align:right;">
0.506
</td>
<td style="text-align:right;">
0.401
</td>
</tr>
<tr>
<td style="text-align:left;">
reason.19
</td>
<td style="text-align:right;">
0.484
</td>
<td style="text-align:right;">
0.458
</td>
<td style="text-align:right;">
0.550
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.434
</td>
<td style="text-align:right;">
0.435
</td>
<td style="text-align:right;">
0.465
</td>
<td style="text-align:right;">
0.423
</td>
<td style="text-align:right;">
0.383
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.407
</td>
<td style="text-align:right;">
0.306
</td>
<td style="text-align:right;">
0.364
</td>
<td style="text-align:right;">
0.419
</td>
<td style="text-align:right;">
0.369
</td>
<td style="text-align:right;">
0.333
</td>
</tr>
<tr>
<td style="text-align:left;">
letter.7
</td>
<td style="text-align:right;">
0.462
</td>
<td style="text-align:right;">
0.471
</td>
<td style="text-align:right;">
0.473
</td>
<td style="text-align:right;">
0.434
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.538
</td>
<td style="text-align:right;">
0.603
</td>
<td style="text-align:right;">
0.523
</td>
<td style="text-align:right;">
0.342
</td>
<td style="text-align:right;">
0.412
</td>
<td style="text-align:right;">
0.442
</td>
<td style="text-align:right;">
0.279
</td>
<td style="text-align:right;">
0.328
</td>
<td style="text-align:right;">
0.443
</td>
<td style="text-align:right;">
0.364
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
letter.33
</td>
<td style="text-align:right;">
0.380
</td>
<td style="text-align:right;">
0.374
</td>
<td style="text-align:right;">
0.440
</td>
<td style="text-align:right;">
0.435
</td>
<td style="text-align:right;">
0.538
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.574
</td>
<td style="text-align:right;">
0.448
</td>
<td style="text-align:right;">
0.335
</td>
<td style="text-align:right;">
0.397
</td>
<td style="text-align:right;">
0.392
</td>
<td style="text-align:right;">
0.318
</td>
<td style="text-align:right;">
0.340
</td>
<td style="text-align:right;">
0.394
</td>
<td style="text-align:right;">
0.369
</td>
<td style="text-align:right;">
0.268
</td>
</tr>
<tr>
<td style="text-align:left;">
letter.34
</td>
<td style="text-align:right;">
0.479
</td>
<td style="text-align:right;">
0.449
</td>
<td style="text-align:right;">
0.473
</td>
<td style="text-align:right;">
0.465
</td>
<td style="text-align:right;">
0.603
</td>
<td style="text-align:right;">
0.574
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.515
</td>
<td style="text-align:right;">
0.365
</td>
<td style="text-align:right;">
0.436
</td>
<td style="text-align:right;">
0.481
</td>
<td style="text-align:right;">
0.256
</td>
<td style="text-align:right;">
0.374
</td>
<td style="text-align:right;">
0.416
</td>
<td style="text-align:right;">
0.348
</td>
<td style="text-align:right;">
0.308
</td>
</tr>
<tr>
<td style="text-align:left;">
letter.58
</td>
<td style="text-align:right;">
0.455
</td>
<td style="text-align:right;">
0.380
</td>
<td style="text-align:right;">
0.480
</td>
<td style="text-align:right;">
0.423
</td>
<td style="text-align:right;">
0.523
</td>
<td style="text-align:right;">
0.448
</td>
<td style="text-align:right;">
0.515
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.330
</td>
<td style="text-align:right;">
0.342
</td>
<td style="text-align:right;">
0.385
</td>
<td style="text-align:right;">
0.371
</td>
<td style="text-align:right;">
0.416
</td>
<td style="text-align:right;">
0.457
</td>
<td style="text-align:right;">
0.439
</td>
<td style="text-align:right;">
0.397
</td>
</tr>
<tr>
<td style="text-align:left;">
matrix.45
</td>
<td style="text-align:right;">
0.431
</td>
<td style="text-align:right;">
0.351
</td>
<td style="text-align:right;">
0.358
</td>
<td style="text-align:right;">
0.383
</td>
<td style="text-align:right;">
0.342
</td>
<td style="text-align:right;">
0.335
</td>
<td style="text-align:right;">
0.365
</td>
<td style="text-align:right;">
0.330
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.511
</td>
<td style="text-align:right;">
0.403
</td>
<td style="text-align:right;">
0.348
</td>
<td style="text-align:right;">
0.307
</td>
<td style="text-align:right;">
0.328
</td>
<td style="text-align:right;">
0.266
</td>
<td style="text-align:right;">
0.309
</td>
</tr>
<tr>
<td style="text-align:left;">
matrix.46
</td>
<td style="text-align:right;">
0.399
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.392
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.412
</td>
<td style="text-align:right;">
0.397
</td>
<td style="text-align:right;">
0.436
</td>
<td style="text-align:right;">
0.342
</td>
<td style="text-align:right;">
0.511
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.383
</td>
<td style="text-align:right;">
0.252
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.350
</td>
<td style="text-align:right;">
0.290
</td>
</tr>
<tr>
<td style="text-align:left;">
matrix.47
</td>
<td style="text-align:right;">
0.401
</td>
<td style="text-align:right;">
0.421
</td>
<td style="text-align:right;">
0.466
</td>
<td style="text-align:right;">
0.407
</td>
<td style="text-align:right;">
0.442
</td>
<td style="text-align:right;">
0.392
</td>
<td style="text-align:right;">
0.481
</td>
<td style="text-align:right;">
0.385
</td>
<td style="text-align:right;">
0.403
</td>
<td style="text-align:right;">
0.383
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.362
</td>
<td style="text-align:right;">
0.407
</td>
<td style="text-align:right;">
0.402
</td>
<td style="text-align:right;">
0.341
</td>
<td style="text-align:right;">
0.342
</td>
</tr>
<tr>
<td style="text-align:left;">
matrix.55
</td>
<td style="text-align:right;">
0.299
</td>
<td style="text-align:right;">
0.314
</td>
<td style="text-align:right;">
0.316
</td>
<td style="text-align:right;">
0.306
</td>
<td style="text-align:right;">
0.279
</td>
<td style="text-align:right;">
0.318
</td>
<td style="text-align:right;">
0.256
</td>
<td style="text-align:right;">
0.371
</td>
<td style="text-align:right;">
0.348
</td>
<td style="text-align:right;">
0.252
</td>
<td style="text-align:right;">
0.362
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.327
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.300
</td>
<td style="text-align:right;">
0.341
</td>
</tr>
<tr>
<td style="text-align:left;">
rotate.3
</td>
<td style="text-align:right;">
0.456
</td>
<td style="text-align:right;">
0.327
</td>
<td style="text-align:right;">
0.386
</td>
<td style="text-align:right;">
0.364
</td>
<td style="text-align:right;">
0.328
</td>
<td style="text-align:right;">
0.340
</td>
<td style="text-align:right;">
0.374
</td>
<td style="text-align:right;">
0.416
</td>
<td style="text-align:right;">
0.307
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.407
</td>
<td style="text-align:right;">
0.327
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.771
</td>
<td style="text-align:right;">
0.665
</td>
<td style="text-align:right;">
0.675
</td>
</tr>
<tr>
<td style="text-align:left;">
rotate.4
</td>
<td style="text-align:right;">
0.491
</td>
<td style="text-align:right;">
0.443
</td>
<td style="text-align:right;">
0.427
</td>
<td style="text-align:right;">
0.419
</td>
<td style="text-align:right;">
0.443
</td>
<td style="text-align:right;">
0.394
</td>
<td style="text-align:right;">
0.416
</td>
<td style="text-align:right;">
0.457
</td>
<td style="text-align:right;">
0.328
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.402
</td>
<td style="text-align:right;">
0.323
</td>
<td style="text-align:right;">
0.771
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.691
</td>
<td style="text-align:right;">
0.682
</td>
</tr>
<tr>
<td style="text-align:left;">
rotate.6
</td>
<td style="text-align:right;">
0.447
</td>
<td style="text-align:right;">
0.408
</td>
<td style="text-align:right;">
0.506
</td>
<td style="text-align:right;">
0.369
</td>
<td style="text-align:right;">
0.364
</td>
<td style="text-align:right;">
0.369
</td>
<td style="text-align:right;">
0.348
</td>
<td style="text-align:right;">
0.439
</td>
<td style="text-align:right;">
0.266
</td>
<td style="text-align:right;">
0.350
</td>
<td style="text-align:right;">
0.341
</td>
<td style="text-align:right;">
0.300
</td>
<td style="text-align:right;">
0.665
</td>
<td style="text-align:right;">
0.691
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.665
</td>
</tr>
<tr>
<td style="text-align:left;">
rotate.8
</td>
<td style="text-align:right;">
0.436
</td>
<td style="text-align:right;">
0.364
</td>
<td style="text-align:right;">
0.401
</td>
<td style="text-align:right;">
0.333
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
0.268
</td>
<td style="text-align:right;">
0.308
</td>
<td style="text-align:right;">
0.397
</td>
<td style="text-align:right;">
0.309
</td>
<td style="text-align:right;">
0.290
</td>
<td style="text-align:right;">
0.342
</td>
<td style="text-align:right;">
0.341
</td>
<td style="text-align:right;">
0.675
</td>
<td style="text-align:right;">
0.682
</td>
<td style="text-align:right;">
0.665
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>The correlation matrix above does not show any negative or low correlations‚Äìwhich is a very good sign! üëç. To check the associations among the items more carefully, we will also create a correlation matrix plot using the <code>ggcorrplot()</code> function from the <strong>ggcorrplot</strong> package <span class="citation">(<a href="#ref-R-ggcorrplot" role="doc-biblioref">Kassambara, 2022</a>)</span>. We will include the <code>hc.order = TRUE</code> argument to perform hierarchical clustering. This will look for groups (i.e., clusters) of items that are strongly associated with each other. If all SAPA items measure the same latent trait, we should see a single cluster of items.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="construct-validation.html#cb8-1" aria-hidden="true" tabindex="-1"></a>ggcorrplot<span class="sc">::</span><span class="fu">ggcorrplot</span>(<span class="at">corr =</span> cormat, <span class="co"># correlation matrix</span></span>
<span id="cb8-2"><a href="construct-validation.html#cb8-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">type =</span> <span class="st">&quot;lower&quot;</span>, <span class="co"># print only the lower part of the correlation matrix</span></span>
<span id="cb8-3"><a href="construct-validation.html#cb8-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">hc.order =</span> <span class="cn">TRUE</span>, <span class="co"># hierarchical clustering</span></span>
<span id="cb8-4"><a href="construct-validation.html#cb8-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">show.diag =</span> <span class="cn">TRUE</span>, <span class="co"># show the diagonal values of 1</span></span>
<span id="cb8-5"><a href="construct-validation.html#cb8-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">lab =</span> <span class="cn">TRUE</span>, <span class="co"># add correlation values as labels</span></span>
<span id="cb8-6"><a href="construct-validation.html#cb8-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">lab_size =</span> <span class="dv">3</span>) <span class="co"># Size of the labels</span></span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons10-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>The figure above shows that the four rotation items have created a cluster (see the cluster on the top-right corner), while the remaining SAPA items have created another cluster (see the cluster on the bottom-left corner). The rotation items are strongly correlated with each other (not surprising given that they all focus on the rotation skills); however, the same items have relatively lower correlations with the other items in the dataset. Also, matrix.55 seems to have relatively low correlations with the items from both clusters.</p>
<p>The findings of hierarchical clustering suggest that the SAPA items may not necessarily be measuring a single latent trait. The items are very likely to be multidimensional. However, hierarchical clustering is not a direct test of dimensionality. To ensure that there is a single factor (i.e., latent trait) underlying the SAPA items, we need to perform factor analysis and evaluate the factor structure of the SAPA items (i.e., dimensionality).</p>
<p><br></p>
</div>
<div id="exploratory-factor-analysis" class="section level4 unnumbered hasAnchor">
<h4>Exploratory Factor Analysis<a href="construct-validation.html#exploratory-factor-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Factor analysis is a widely-used statistical technique that aims to explain the common variability among a set of observed variables and transform the variables into a reduced set of variables known as factors (or dimensions). At the core of factor analysis is the desire to reduce the dimensionality of the data from <span class="math inline">\(p\)</span> observed variables to <span class="math inline">\(q\)</span> factors, such that <span class="math inline">\(q &lt; p\)</span>. During instrument development or when there are no prior beliefs about the dimensionality of an existing instrument, exploratory factor analysis (EFA) should be considered to investigate the factorial structure of the instrument. To perform EFA, we need to specify the number of factors to extract, how to rotate factors (if the expected number of factors &gt; 1), and which type of estimation method should be used depending on the nature of the data (i.e., categorical, ordinal, or continuous).</p>
<p>The <strong>psych</strong> package includes several functions to perform EFA with different estimation methods. In this example, we will use the <code>fa()</code> function in the <strong>psych</strong> package to perform EFA. To use the function, we need to specify the following items:</p>
<ul>
<li>r = Response data (either raw data or a correlation matrix)</li>
<li>n.obs = Number of observations in the data (necessary only when using a correlation matrix)</li>
<li>nfactors = Number of factors that we expect to find in the data</li>
<li>rotate = Type of rotation if <span class="math inline">\(n &gt; 1\)</span>. We can use ‚Äúvarimax‚Äù for an orthogonal rotation that assumes no correlation between factors or ‚Äúoblimin‚Äù for an oblique rotation that assumes factors are somewhat correlated</li>
<li>fm = Factor analysis method. We will use ‚Äúml‚Äù (i.e., maximum likelihood estimation) for EFA</li>
<li>cor = How to find the correlations when using raw data. For continuous variable, use <code>cor = "Pearson"</code> (Pearson correlation); for dichotomous variables, use <code>cor = "tet"</code> (tetrachoric correlation); for polytomous variables (e.g., Likert scales), use <code>cor = "poly"</code> (polychoric correlation).</li>
</ul>
<p>First, we will try a one-factor model, evaluate model fit, and determine whether a one-factor (i.e., unidimensional) structure is acceptable for the SAPA items:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="construct-validation.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try one-factor EFA model --&gt; nfactors = 1</span></span>
<span id="cb9-2"><a href="construct-validation.html#cb9-2" aria-hidden="true" tabindex="-1"></a>efa.model1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(<span class="at">r =</span> sapa, <span class="at">nfactors =</span> <span class="dv">1</span>, <span class="at">fm =</span> <span class="st">&quot;ml&quot;</span>, <span class="at">cor =</span> <span class="st">&quot;tet&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="construct-validation.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results </span></span>
<span id="cb10-2"><a href="construct-validation.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(efa.model1, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="co"># Show the factor loadings sorted by absolute value</span></span></code></pre></div>
<pre><code>Factor Analysis using method =  ml
Call: psych::fa(r = sapa, nfactors = 1, fm = &quot;ml&quot;, cor = &quot;tet&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
           V  ML1   h2   u2 com
rotate.4  14 0.75 0.57 0.43   1
reason.17  3 0.71 0.50 0.50   1
rotate.6  15 0.70 0.50 0.50   1
reason.4   1 0.70 0.49 0.51   1
rotate.3  13 0.70 0.48 0.52   1
letter.34  7 0.67 0.45 0.55   1
letter.58  8 0.66 0.43 0.57   1
letter.7   5 0.66 0.43 0.57   1
rotate.8  16 0.66 0.43 0.57   1
reason.19  4 0.63 0.40 0.60   1
reason.16  2 0.63 0.40 0.60   1
matrix.47 11 0.61 0.38 0.62   1
letter.33  6 0.61 0.38 0.62   1
matrix.46 10 0.54 0.30 0.70   1
matrix.45  9 0.53 0.28 0.72   1
matrix.55 12 0.47 0.22 0.78   1

                ML1
SS loadings    6.64
Proportion Var 0.42

Mean item complexity =  1
Test of the hypothesis that 1 factor is sufficient.

The degrees of freedom for the null model are  120  and the objective function was  8.04 with Chi Square of  12198
The degrees of freedom for the model are 104  and the objective function was  1.85 

The root mean square of the residuals (RMSR) is  0.08 
The df corrected root mean square of the residuals is  0.09 

The harmonic number of observations is  1523 with the empirical chi square  2331  with prob &lt;  0 
The total number of observations was  1525  with Likelihood Chi Square =  2801  with prob &lt;  0 

Tucker Lewis Index of factoring reliability =  0.742
RMSEA index =  0.13  and the 90 % confidence intervals are  0.126 0.135
BIC =  2039
Fit based upon off diagonal values = 0.96
Measures of factor score adequacy             
                                                   ML1
Correlation of (regression) scores with factors   0.96
Multiple R square of scores with factors          0.92
Minimum correlation of possible factor scores     0.85</code></pre>
<p>The output shows the factor loadings for each item (see the <code>ML1</code> column referring the first factor produced by the maximum likelihood (ML) method) and the proportion of explained variance (42%; see <code>Proportion Var</code>). The factor loadings seem to be high enough based on the rule of thumb of <span class="math inline">\(\lambda \geq 0.3\)</span>. We can determine model fit based on model fit indices of root mean square of residuals (RMSR), root mean square error of approximation (RMSEA), and Tucker-Lewis Index. We can use <span class="citation">Hu &amp; Bentler (<a href="#ref-hu1999cutoff" role="doc-biblioref">1999</a>)</span>‚Äôs guidelines for these model fit indices: Tucker-Lewis index (TLI) &gt; .95, RMSEA &lt; .06, and RMSR near zero indicate good model fit. The fit measures in the output show that the one-factor model does not necessarily fit the sapa dataset very well.</p>
<p>In the output, <span class="math inline">\(h^2\)</span> shows the amount of variance in the item/variable explained by the (retained) factors. It is the sum of the squared loadings (i.e., communality), <span class="math inline">\(u^2\)</span>, which is <span class="math inline">\(1 - h^2\)</span>, shows residual variance (i.e., uniqueness), and com (i.e., item complexity = <span class="math inline">\({(Œ£ Œª_i^2)^2}/{Œ£ Œª_i^4}\)</span> where <span class="math inline">\(\lambda_i\)</span> is the factor loading on the <span class="math inline">\(i^{th}\)</span> factor) shows how much an item reflects a single construct (e.g., com equals 1 if an item loads only on one factor, 2 if evenly loads on two factors, etc.).</p>
<p>If we wanted to report the chi-square (<span class="math inline">\(\chi^2\)</span>) test for our model, we would use the following part in the output: <code>The total number of observations was  1525  with Likelihood Chi Square =  2801  with prob &lt;  0</code>. We can also extract these values from the model using <code>efa.model1$STATISTIC</code>, <code>efa.model1$dof</code>, <code>efa.model1$PVAL</code>,</p>
<p>Next, we will fit a two-factor model to the sapa dataset:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="construct-validation.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try two-factor EFA model --&gt; nfactors=2</span></span>
<span id="cb12-2"><a href="construct-validation.html#cb12-2" aria-hidden="true" tabindex="-1"></a>efa.model2 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(sapa, <span class="at">nfactors =</span> <span class="dv">2</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>, <span class="at">fm =</span> <span class="st">&quot;ml&quot;</span>, <span class="at">cor =</span> <span class="st">&quot;tet&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="construct-validation.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results </span></span>
<span id="cb13-2"><a href="construct-validation.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(efa.model2, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  ml
Call: psych::fa(r = sapa, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;, 
    cor = &quot;tet&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
          item   ML1   ML2   h2   u2 com
letter.34    7  0.80 -0.09 0.56 0.44 1.0
letter.7     5  0.78 -0.08 0.54 0.46 1.0
letter.33    6  0.70 -0.05 0.45 0.55 1.0
reason.17    3  0.67  0.08 0.52 0.48 1.0
reason.19    4  0.63  0.04 0.43 0.57 1.0
reason.16    2  0.60  0.07 0.42 0.58 1.0
matrix.46   10  0.59 -0.01 0.34 0.66 1.0
matrix.47   11  0.58  0.08 0.40 0.60 1.0
letter.58    8  0.57  0.14 0.45 0.55 1.1
reason.4     1  0.57  0.18 0.49 0.51 1.2
matrix.45    9  0.54  0.02 0.30 0.70 1.0
matrix.55   12  0.34  0.17 0.22 0.78 1.5
rotate.3    13 -0.04  0.89 0.74 0.26 1.0
rotate.8    16 -0.04  0.83 0.64 0.36 1.0
rotate.4    14  0.08  0.82 0.77 0.23 1.0
rotate.6    15  0.08  0.74 0.64 0.36 1.0

                       ML1  ML2
SS loadings           4.88 3.01
Proportion Var        0.31 0.19
Cumulative Var        0.31 0.49
Proportion Explained  0.62 0.38
Cumulative Proportion 0.62 1.00

 With factor correlations of 
     ML1  ML2
ML1 1.00 0.64
ML2 0.64 1.00

Mean item complexity =  1.1
Test of the hypothesis that 2 factors are sufficient.

The degrees of freedom for the null model are  120  and the objective function was  8.04 with Chi Square of  12198
The degrees of freedom for the model are 89  and the objective function was  0.64 

The root mean square of the residuals (RMSR) is  0.04 
The df corrected root mean square of the residuals is  0.05 

The harmonic number of observations is  1523 with the empirical chi square  564  with prob &lt;  4.3e-70 
The total number of observations was  1525  with Likelihood Chi Square =  969  with prob &lt;  7.1e-148 

Tucker Lewis Index of factoring reliability =  0.902
RMSEA index =  0.081  and the 90 % confidence intervals are  0.076 0.085
BIC =  317
Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   ML1  ML2
Correlation of (regression) scores with factors   0.95 0.95
Multiple R square of scores with factors          0.90 0.91
Minimum correlation of possible factor scores     0.81 0.82</code></pre>
<p>Based on the factor loadings listed under the <code>ML1</code> and <code>ML2</code> columns, we see that the first 12 items are highly loaded on the first factor whereas the last four items (i.e., rotation items) are highly loaded on the second factor. This finding is aligned with what we have observed in the correlation matrix plot earlier.</p>
<p>The rest of the output shows that the first factor explains 31% of the total variance while the second factor explains 19% of the total variance (see <code>Proportion Var</code>). Compared to the one-factor model, the two-factor model explains an additional 8% of variance in the data. The two factors seem to be moderately correlated (<span class="math inline">\(r = .64\)</span>). The model fit indices show that the two-factor model fits the data better, although the model fit indices still do not entirely meet the criteria for sufficient model fit. We can plot the factor loadings to get a sense of how the items relate to the two factors (note that this plot becomes much more complex as we plot 3 or more factors).</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="construct-validation.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(efa.model2)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons12b-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>So far, the one-factor and two-factor models did not fit the data adequately. The two-factor model separated the <em>rotation</em> items from the rest of the SAPA items. Do we expect to find four <em>meaningful</em> factors based on each domain covered in the SAPA items (i.e., verbal reasoning, letter series, matrix reasoning, and spatial rotations)? If this is the case, we can try a four-factor model and evaluate the fit and loadings of the model.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="construct-validation.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try four-factor EFA model --&gt; nfactors=4</span></span>
<span id="cb16-2"><a href="construct-validation.html#cb16-2" aria-hidden="true" tabindex="-1"></a>efa.model4 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(sapa, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">rotate =</span> <span class="st">&quot;oblimin&quot;</span>, <span class="at">fm =</span> <span class="st">&quot;ml&quot;</span>, <span class="at">cor =</span> <span class="st">&quot;tet&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="construct-validation.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results </span></span>
<span id="cb17-2"><a href="construct-validation.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(efa.model4, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>Factor Analysis using method =  ml
Call: psych::fa(r = sapa, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;, 
    cor = &quot;tet&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
          item   ML3   ML4   ML1   ML2   h2    u2 com
rotate.3    13  0.88  0.03 -0.08  0.02 0.75 0.254 1.0
rotate.4    14  0.84  0.14 -0.07 -0.01 0.78 0.216 1.1
rotate.8    16  0.80 -0.13  0.08  0.06 0.65 0.353 1.1
rotate.6    15  0.72 -0.03  0.21 -0.05 0.66 0.345 1.2
letter.34    7 -0.01  0.79  0.00  0.01 0.64 0.365 1.0
letter.7     5 -0.01  0.76  0.03 -0.01 0.60 0.399 1.0
letter.33    6  0.02  0.66  0.02  0.02 0.49 0.507 1.0
letter.58    8  0.18  0.46  0.12  0.01 0.45 0.547 1.5
matrix.47   11  0.12  0.34  0.15  0.16 0.39 0.608 2.1
reason.17    3  0.00  0.03  0.89  0.01 0.83 0.167 1.0
reason.4     1  0.19  0.17  0.38  0.15 0.51 0.486 2.3
reason.19    4  0.07  0.28  0.34  0.11 0.44 0.563 2.3
reason.16    2  0.10  0.27  0.34  0.07 0.42 0.579 2.2
matrix.45    9  0.00 -0.01 -0.01  0.97 0.92 0.078 1.0
matrix.46   10  0.02  0.29  0.08  0.35 0.38 0.616 2.1
matrix.55   12  0.19  0.13  0.09  0.20 0.23 0.775 3.1

                       ML3  ML4  ML1  ML2
SS loadings           3.12 2.83 1.77 1.43
Proportion Var        0.19 0.18 0.11 0.09
Cumulative Var        0.19 0.37 0.48 0.57
Proportion Explained  0.34 0.31 0.19 0.16
Cumulative Proportion 0.34 0.65 0.84 1.00

 With factor correlations of 
     ML3  ML4  ML1  ML2
ML3 1.00 0.53 0.53 0.38
ML4 0.53 1.00 0.63 0.48
ML1 0.53 0.63 1.00 0.41
ML2 0.38 0.48 0.41 1.00

Mean item complexity =  1.6
Test of the hypothesis that 4 factors are sufficient.

The degrees of freedom for the null model are  120  and the objective function was  8.04 with Chi Square of  12198
The degrees of freedom for the model are 62  and the objective function was  0.23 

The root mean square of the residuals (RMSR) is  0.02 
The df corrected root mean square of the residuals is  0.03 

The harmonic number of observations is  1523 with the empirical chi square  163  with prob &lt;  4.5e-11 
The total number of observations was  1525  with Likelihood Chi Square =  355  with prob &lt;  9.6e-43 

Tucker Lewis Index of factoring reliability =  0.953
RMSEA index =  0.056  and the 90 % confidence intervals are  0.05 0.061
BIC =  -99.1
Fit based upon off diagonal values = 1
Measures of factor score adequacy             
                                                   ML3  ML4  ML1  ML2
Correlation of (regression) scores with factors   0.96 0.93 0.93 0.96
Multiple R square of scores with factors          0.91 0.86 0.87 0.93
Minimum correlation of possible factor scores     0.83 0.72 0.74 0.85</code></pre>
<p>The four-factor model yielded the best model fit results: <span class="math inline">\(RMSEA = 0.056\)</span>, <span class="math inline">\(RMSR = 0.02\)</span>, and Tucker Lewis Index is 0.953. However, our assumption of creating a separate factor for each domain did not entirely hold. The output shows that <code>matrix.47</code> is mostly loaded on <code>ML4</code> with the letter series items, and <code>matrix.55</code> is not sufficiently loaded on any of the factors. At this point, we need to make a theoretical decision informed by the statistical output. Should we keep the matrix reasoning items in the dataset and use the four-factor model? Or, instead, can we remove the matrix items from the dataset and evaluate the factor structure with the remaining items (assuming three factors)? We could also fit a four-factor CFA model to the data to investigate the model fit based on the theoretical model that the items of each domain define a separate factor (i.e., forcing the matrix items to create a matrix reasoning factor, verbal reasoning items to create a verbal reasoning factor, and so on).</p>
<p>Now, let‚Äôs see the scree plot for the four-factor model. We will extract the eigenvalues from the common factor solution, create a separate dataset with them, and then visualize the values in a scree plot:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="construct-validation.html#cb19-1" aria-hidden="true" tabindex="-1"></a>data_eigen <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">ev =</span> efa.model4<span class="sc">$</span>values, </span>
<span id="cb19-2"><a href="construct-validation.html#cb19-2" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># 16 eigenvalues due to having 16 items in SAPA</span></span>
<span id="cb19-3"><a href="construct-validation.html#cb19-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">factor_number=</span><span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>)) </span>
<span id="cb19-4"><a href="construct-validation.html#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="construct-validation.html#cb19-5" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">ggplot</span>(data_eigen, </span>
<span id="cb19-6"><a href="construct-validation.html#cb19-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">aes</span>(<span class="at">x =</span> factor_number, <span class="at">y =</span> ev, <span class="at">group =</span> <span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb19-7"><a href="construct-validation.html#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb19-8"><a href="construct-validation.html#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb19-9"><a href="construct-validation.html#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>(<span class="at">base_size=</span><span class="dv">15</span>) <span class="sc">+</span></span>
<span id="cb19-10"><a href="construct-validation.html#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Factor number&quot;</span>) <span class="sc">+</span> </span>
<span id="cb19-11"><a href="construct-validation.html#cb19-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Eigenvalue&quot;</span>)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons15-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>As the scree plot demonstrates, identifying a clear breaking (or elbow) point is quite difficult. In our example, if we accept the 4th point as the elbow point, then the scree plot suggests that the model should have four factors. However, there is a less pronounced slope change between 3 and 4 factors. So, the scree plot might lead us to consider either three- or four-factor solutions. At this point, the interpretability of the extracted factors and their factor loadings may serve as better criteria in the selection of a meaningful factor solution.</p>
<p>The <strong>psych</strong> package also includes an omega (<span class="math inline">\(\omega\)</span>) function that fits a bi-factor EFA model to the data. This particular model assumes that there is a general factor associated with every item, as well as unique factors based on the constructs underlying the items. So, the function performs hierarchical factor analysis in the background, without requiring an explicit definition of the bi-factor structure.</p>
<p>Since the SAPA items are <em>expected</em> to measure the general intelligence (<em>g</em>), we can assume that each domain (verbal reasoning, letter series, matrix reasoning, and spatial rotations) will define a separate factor but all the SAPA items will define the general intelligence.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="construct-validation.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bi-factor EFA model</span></span>
<span id="cb20-2"><a href="construct-validation.html#cb20-2" aria-hidden="true" tabindex="-1"></a>omega.model <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">omega</span>(sapa, <span class="at">nfactors =</span> <span class="dv">4</span>, <span class="at">fm =</span> <span class="st">&quot;ml&quot;</span>, <span class="at">poly =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons16-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="construct-validation.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results </span></span>
<span id="cb21-2"><a href="construct-validation.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(omega.model)</span></code></pre></div>
<pre><code>Omega 
Call: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, 
    digits = digits, title = title, sl = sl, labels = labels, 
    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, 
    covar = covar)
Alpha:                 0.92 
G.6:                   0.93 
Omega Hierarchical:    0.76 
Omega H asymptotic:    0.8 
Omega Total            0.94 

Schmid Leiman Factor loadings greater than  0.2 
             g   F1*   F2*   F3*   F4*   h2   u2   p2
reason.4  0.64              0.24       0.51 0.49 0.80
reason.16 0.59              0.21       0.42 0.58 0.81
reason.17 0.71              0.57       0.83 0.17 0.61
reason.19 0.60              0.22       0.44 0.56 0.81
letter.7  0.64        0.44             0.60 0.40 0.68
letter.33 0.59        0.38             0.49 0.51 0.70
letter.34 0.65        0.46             0.64 0.36 0.67
letter.58 0.60        0.26             0.45 0.55 0.79
matrix.45 0.53                    0.80 0.92 0.08 0.30
matrix.46 0.52                    0.29 0.38 0.62 0.69
matrix.47 0.56        0.20             0.39 0.61 0.81
matrix.55 0.41                         0.23 0.77 0.75
rotate.3  0.56  0.66                   0.75 0.25 0.42
rotate.4  0.62  0.63                   0.78 0.22 0.49
rotate.6  0.58  0.54                   0.66 0.34 0.52
rotate.8  0.52  0.60                   0.65 0.35 0.42

With Sums of squares  of:
   g  F1*  F2*  F3*  F4* 
5.49 1.56 0.76 0.52 0.80 

general/max  3.51   max/min =   2.99
mean percent general =  0.64    with sd =  0.16 and cv of  0.26 
Explained Common Variance of the general factor =  0.6 

The degrees of freedom are 62  and the fit is  0.23 
The number of observations was  1525  with Chi Square =  355  with prob &lt;  9.6e-43
The root mean square of the residuals is  0.02 
The df corrected root mean square of the residuals is  0.03
RMSEA index =  0.056  and the 10 % confidence intervals are  0.05 0.061
BIC =  -99.1

Compare this with the adequacy of just a general factor and no group factors
The degrees of freedom for just the general factor are 104  and the fit is  2.03 
The number of observations was  1525  with Chi Square =  3077  with prob &lt;  0
The root mean square of the residuals is  0.11 
The df corrected root mean square of the residuals is  0.12 

RMSEA index =  0.137  and the 10 % confidence intervals are  0.133 0.141
BIC =  2315 

Measures of factor score adequacy             
                                                 g  F1*   F2*  F3*  F4*
Correlation of scores with factors            0.88 0.85  0.66 0.72 0.90
Multiple R square of scores with factors      0.78 0.71  0.43 0.52 0.81
Minimum correlation of factor score estimates 0.56 0.43 -0.14 0.04 0.62

 Total, General and Subset omega for each subset
                                                 g  F1*  F2*  F3*  F4*
Omega total for total scores and subscales    0.94 0.90 0.83 0.78 0.71
Omega general for total scores and subscales  0.76 0.42 0.63 0.63 0.41
Omega group for total scores and subscales    0.11 0.48 0.20 0.15 0.30</code></pre>
<p>In the output, the factor loadings are for the general (g) and specific factors (F1 to F4) are provided, as well as the communality and uniquenesses values. In addition, there is a column called <code>p2</code>, which is considered a diagnostic tool for the appropriateness of a hierarchical model. It is defined as ‚Äúpercent of the common variance for each variable that is general factor variance‚Äù. This is calculated as <span class="math inline">\(g^2/h^2\)</span>.</p>
<p>The first two pieces of the reliability output refer to the coefficient alpha and G6 coefficients. <span class="math inline">\(\omega_{hierarchical}\)</span> refers to the loadings of the general factor and <span class="math inline">\(\omega_{total}\)</span> refers to reliability based on all the general and specific factor loadings. Under ‚ÄúModel test results‚Äù, we can see that there are two models considered‚Äìa model with general and specific factors and another model with no specific factors.</p>
<p>Regarding the part labeled as ‚ÄúVariance accounted for by group and specific factors‚Äù, the help page for the omega function through <code>?omega</code> shows the following information:</p>
<blockquote>
<p>The notion of omega may be applied to the individual factors as well as the overall test. A typical use of omega is to identify subscales of a total inventory. Some of that variability is due to the general factor of the inventory, some to the specific variance of each subscale. Thus, we can find a number of different omega estimates: what percentage of the variance of the items identified with each subfactor is actually due to the general factor. What variance is common but unique to the subfactor, and what is the total reliable variance of each subfactor. These results are reported in omega.group object and in the last few lines of the normal output.</p>
</blockquote>
<p>It is a bit complicated but overall, Omega total refers to the total variance accounted for by the general factor as well as the subscales, whereas Omega general refers to the variance accounted for by the general factor.</p>
<hr />
</div>
<div id="exercises" class="section level4 unnumbered hasAnchor">
<h4>Exercises<a href="construct-validation.html#exercises" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><p>Run the four-factor EFA model using <code>rotate = "varimax"</code> for orthogonal rotation and check the model fit (i.e., whether forcing the factors to be uncorrelated improved the model fit).</p></li>
<li><p>The <strong>psych</strong> package help page for the <code>fa</code> function has the following information:</p></li>
</ol>
<blockquote>
<p>A very strong argument against using MLE is found in the chapter by MacCallum, Brown and Cai (2007) who show that OLS approaches produce equivalent solutions most of the time, and better solutions some of the time. This particularly in the case of models with some unmodeled small factors. (See sim.minor to generate such data.) Principal axes may be used in cases when maximum likelihood solutions fail to converge, although fm=‚Äúminres‚Äù will also do that and tends to produce better (smaller RMSEA) solutions.</p>
</blockquote>
<p>Run the four-factor EFA model using <code>fm = "pa"</code> and <code>fm = "minres"</code> and check whether the resulting models produce smaller residuals and RMSEA values.</p>
<p><br></p>
<ol start="3" style="list-style-type: decimal">
<li>Now, let‚Äôs simulate some ordinal data (e.g., Likert scales) using the Graded Response Model and check which estimator would yield better results. We will use the <strong>mirt</strong> <span class="citation">(<a href="#ref-R-mirt" role="doc-biblioref">Chalmers, 2022</a>)</span> and <strong>MASS</strong> <span class="citation">(<a href="#ref-R-MASS" role="doc-biblioref">Ripley, 2022</a>)</span> packages for data simulation (check out <code>?psych::sim</code> for built-in simulation functions in the <strong>psych</strong> package). The following function simulates 12 items based on a two-factor model (6 items per factor). We can determine the sample size using <code>sample.size</code> and the correlation between the two factors using <code>cor</code>. The final <code>seed</code> argument allows to fix the seed in the simulation so that we can create the same dataset (or different datasets) in the future. The first six items are mostly loaded on the first dimension, while the second set of 6 items are mostly loaded on the second dimension. The function returns a list consisting of the factor scores, item parameters, and response data.</li>
</ol>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="construct-validation.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s define a simulation function called simGRMdata</span></span>
<span id="cb23-2"><a href="construct-validation.html#cb23-2" aria-hidden="true" tabindex="-1"></a>simGRMdata <span class="ot">&lt;-</span> <span class="cf">function</span>(sample.size, cor, seed) {</span>
<span id="cb23-3"><a href="construct-validation.html#cb23-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-4"><a href="construct-validation.html#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(<span class="st">&quot;mirt&quot;</span>)</span>
<span id="cb23-5"><a href="construct-validation.html#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(<span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb23-6"><a href="construct-validation.html#cb23-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-7"><a href="construct-validation.html#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Seed will allow us to generate the same data again later on</span></span>
<span id="cb23-8"><a href="construct-validation.html#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(seed)) {<span class="fu">set.seed</span>(seed)}</span>
<span id="cb23-9"><a href="construct-validation.html#cb23-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-10"><a href="construct-validation.html#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define multidimensional abilities (i.e., factor scores)</span></span>
<span id="cb23-11"><a href="construct-validation.html#cb23-11" aria-hidden="true" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="at">n =</span> sample.size, </span>
<span id="cb23-12"><a href="construct-validation.html#cb23-12" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># mean for factor scores</span></span>
<span id="cb23-13"><a href="construct-validation.html#cb23-13" aria-hidden="true" tabindex="-1"></a>                         <span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb23-14"><a href="construct-validation.html#cb23-14" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># variance-covariance matrix of matrix scores</span></span>
<span id="cb23-15"><a href="construct-validation.html#cb23-15" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,cor,cor,<span class="dv">1</span>),<span class="dv">2</span>,<span class="dv">2</span>)) </span>
<span id="cb23-16"><a href="construct-validation.html#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="construct-validation.html#cb23-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Generate slope (i.e., discrimination) parameters</span></span>
<span id="cb23-18"><a href="construct-validation.html#cb23-18" aria-hidden="true" tabindex="-1"></a>  a1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">min =</span> <span class="fl">0.9</span>, <span class="at">max =</span> <span class="fl">2.4</span>), <span class="co"># First 6 items load heavily on the first factor</span></span>
<span id="cb23-19"><a href="construct-validation.html#cb23-19" aria-hidden="true" tabindex="-1"></a>          <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">min =</span> <span class="fl">0.1</span>, <span class="at">max =</span> <span class="fl">0.4</span>)) <span class="co"># But they load low on the second factor</span></span>
<span id="cb23-20"><a href="construct-validation.html#cb23-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-21"><a href="construct-validation.html#cb23-21" aria-hidden="true" tabindex="-1"></a>  a2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">min =</span> <span class="fl">0.1</span>, <span class="at">max =</span> <span class="fl">0.4</span>), <span class="co"># Second six items load low on the first factor</span></span>
<span id="cb23-22"><a href="construct-validation.html#cb23-22" aria-hidden="true" tabindex="-1"></a>          <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">min =</span> <span class="fl">0.9</span>, <span class="at">max =</span> <span class="fl">2.4</span>)) <span class="co"># But they load heavily on the second factor</span></span>
<span id="cb23-23"><a href="construct-validation.html#cb23-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-24"><a href="construct-validation.html#cb23-24" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(a1, a2), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb23-25"><a href="construct-validation.html#cb23-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-26"><a href="construct-validation.html#cb23-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Generate intercept (i.e., difficulty) parameters</span></span>
<span id="cb23-27"><a href="construct-validation.html#cb23-27" aria-hidden="true" tabindex="-1"></a>  b1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">min =</span> <span class="fl">0.67</span>, <span class="at">max =</span> <span class="dv">2</span>)</span>
<span id="cb23-28"><a href="construct-validation.html#cb23-28" aria-hidden="true" tabindex="-1"></a>  b2 <span class="ot">&lt;-</span> b1 <span class="sc">-</span> <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">min =</span> <span class="fl">0.67</span>, <span class="at">max =</span> <span class="fl">1.34</span>)</span>
<span id="cb23-29"><a href="construct-validation.html#cb23-29" aria-hidden="true" tabindex="-1"></a>  b3 <span class="ot">&lt;-</span> b2 <span class="sc">-</span> <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">12</span>, <span class="at">min =</span> <span class="fl">0.67</span>, <span class="at">max =</span> <span class="fl">1.34</span>)</span>
<span id="cb23-30"><a href="construct-validation.html#cb23-30" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(b1, b2, b3), <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb23-31"><a href="construct-validation.html#cb23-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-32"><a href="construct-validation.html#cb23-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Generate item responses based on GRM</span></span>
<span id="cb23-33"><a href="construct-validation.html#cb23-33" aria-hidden="true" tabindex="-1"></a>  resp <span class="ot">&lt;-</span> mirt<span class="sc">::</span><span class="fu">simdata</span>(<span class="at">a =</span> a, <span class="at">d =</span> b, <span class="at">itemtype =</span> <span class="st">&#39;graded&#39;</span>, <span class="at">Theta =</span> theta)</span>
<span id="cb23-34"><a href="construct-validation.html#cb23-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-35"><a href="construct-validation.html#cb23-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Return all the parameters and data</span></span>
<span id="cb23-36"><a href="construct-validation.html#cb23-36" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">theta =</span> theta,</span>
<span id="cb23-37"><a href="construct-validation.html#cb23-37" aria-hidden="true" tabindex="-1"></a>                <span class="at">parameters =</span> <span class="fu">cbind</span>(a, b),</span>
<span id="cb23-38"><a href="construct-validation.html#cb23-38" aria-hidden="true" tabindex="-1"></a>                <span class="at">response =</span> resp)</span>
<span id="cb23-39"><a href="construct-validation.html#cb23-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-40"><a href="construct-validation.html#cb23-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb23-41"><a href="construct-validation.html#cb23-41" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-42"><a href="construct-validation.html#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="construct-validation.html#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Example dataset</span></span>
<span id="cb23-44"><a href="construct-validation.html#cb23-44" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">simGRMdata</span>(<span class="at">sample.size =</span> <span class="dv">1000</span>, <span class="at">cor =</span> <span class="fl">0.8</span>, <span class="at">seed =</span> <span class="dv">2023</span>)</span>
<span id="cb23-45"><a href="construct-validation.html#cb23-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-46"><a href="construct-validation.html#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="co"># View the factor scores</span></span>
<span id="cb23-47"><a href="construct-validation.html#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mydata<span class="sc">$</span>theta)</span>
<span id="cb23-48"><a href="construct-validation.html#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="construct-validation.html#cb23-49" aria-hidden="true" tabindex="-1"></a><span class="co"># View the parameters</span></span>
<span id="cb23-50"><a href="construct-validation.html#cb23-50" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mydata<span class="sc">$</span>parameters)</span>
<span id="cb23-51"><a href="construct-validation.html#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="construct-validation.html#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="co"># View the response data</span></span>
<span id="cb23-53"><a href="construct-validation.html#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mydata<span class="sc">$</span>response)</span></code></pre></div>
<p>Using the function we defined above, generate datasets with different sample sizes and inter-factor correlations and then apply EFA to the response dataset to evaluate the dimensionality. You can use <code>fm = "pa"</code> and <code>fm = "ml"</code> in the estimation. Compare the performance of the two estimation methods.</p>
<p><br></p>
<hr />
</div>
</div>
<div id="example-2-financial-well-being-scale" class="section level3 unnumbered hasAnchor">
<h3>Example 2: Financial Well-Being Scale<a href="construct-validation.html#example-2-financial-well-being-scale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the second example, we will use the <a href="https://www.consumerfinance.gov/">Consumer Financial Protection Bureau (CFPB)</a>‚Äôs Financial Well-Being Scale to demonstrate other factor analytic techniques. CFPB defines financial well-being as follows:</p>
<blockquote>
<p>Financial well-being is a state of being wherein a person can fully meet current and
ongoing financial obligations, can feel secure in their financial future, and is able to
make choices that allow them to enjoy life.</p>
</blockquote>
<p>To measure the construct of financial well-being, CFPB created the <a href="https://www.consumerfinance.gov/consumer-tools/financial-well-being/">Financial Well-Being Scale</a> that consists of ten rating scale items. The items cover all four elements of the CFPB‚Äôs definition of financial well-being: control over finances, capacity to absorb a financial shock, being on track to meet financial goals, and having the financial freedom to enjoy life, using both positive and negative phrasing. Figure 1 shows a list of the items and their response options.</p>
<div class="figure">
<img src="images/fw1.jpg" alt="" />
<p class="caption"><strong>Figure 1:</strong> Items in the Financial Well-Being Scale (Source: Consumer Financial Protection Bureau)</p>
</div>
<p>The CFPB‚Äôs <a href="https://files.consumerfinance.gov/f/documents/201705_cfpb_financial-well-being-scale-technical-report.pdf">technical report</a> on the Financial Well-Being (FWB) Scale indicates that the researchers tested several different models, including a unidimensional model, several multidimensional models defined a <em>priori</em> by substantive item content, and other models indicated by initial exploratory analyses that reflected methodological considerations (such as positive versus negative item wording). Although the instrument was supposed to measure financial well-being as a single (i.e., unidimensional) construct, the researchers found that the bi-factor model fit the data best, with a general factor related to the latent financial well-being construct and two additional factors associated with the polarity of the item (i.e., whether the item was phrased negatively or positively).</p>
<p>For demonstration purposes, we will assume that we do <em>not</em> have any priori hypothesis about the factorial structure (i.e., dimensionality) of the FWB Scale, or we believe that the construct of financial well-being may be unidimensional though we are not entirely sure at this point. Therefore, we will begin our analysis with an exploratory approach‚ÄìParallel Analysis‚Äìto evaluate the dimensionality of this scale. Once we get an idea of what the factor structure may look like, we will switch to confirmatory factor analysis (CFA) to verify the structure. The dataset for this example is ‚Äúfinance.csv‚Äù. This dataset consists of 3822 individuals‚Äô responses to 10 items in the FWB Scale, demographic variables, and additional variables related to financial well-being. The finance dataset can be downloaded from <a href="data_and_codes/finance.csv"><strong>finance.csv</strong></a>. In addition, the R codes for the analyses presented in this section are available in <a href="data_and_codes/example2.R"><strong>example2.R</strong></a>.</p>
<div id="exploratory-data-analysis-1" class="section level4 unnumbered hasAnchor">
<h4>Exploratory Data Analysis<a href="construct-validation.html#exploratory-data-analysis-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We will begin our analysis by conducting exploratory data analysis to check our dataset. We will first import <a href="data_and_codes/finance.csv">finance.csv</a> into R, save it as ‚Äúfinance‚Äù, and then review the variables in the dataset using descriptive statistics and visualizations.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="construct-validation.html#cb24-1" aria-hidden="true" tabindex="-1"></a>finance <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;finance.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Using the <code>head()</code> function, we can now view the first 6 rows of the <code>finance</code> dataset:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="construct-validation.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(finance)</span></code></pre></div>
<pre><code>  respondent_id   age gender              education                                     employment
1          7740 35-44   Male High school degree/GED Work full-time for an employer or the military
2         13699 35-44   Male Some college/Associate Work full-time for an employer or the military
3          7267 35-44   Male High school degree/GED                                        Refused
4          7375 25-34   Male High school degree/GED Work full-time for an employer or the military
5         10910 25-34   Male      Bachelor&#39;s degree Work full-time for an employer or the military
6         11079 35-44 Female      Bachelor&#39;s degree                                      Homemaker
      marital_status fwb1_1 fwb1_2 fwb1_3 fwb1_4 fwb1_5 fwb1_6 fwb2_1 fwb2_2 fwb2_3 fwb2_4 raise2000
1 Divorced/Separated      2      2      3      3      3      4      2      2      2      3         3
2 Divorced/Separated      3      3      3      3      3      3      3      3      3      3         4
3 Divorced/Separated      3      3      3      3      3      3      3      3      3      3         8
4            Married      3      3      3      3      3      3      3      3      3      3         2
5            Married      5      1      1      1      1      1      2      5      2      2         4
6            Married      1      3      2      3      3      3      3      2      1      4         4
  financial_knowledge debt_collector hardship_food hardship_doctor
1                   5              1             1               1
2                   5              0             1               1
3                  -1             -1             2               2
4                   4              8             2               2
5                   6              0             1               1
6                   5              0             1               1</code></pre>
<p>The variables in the datasets are as follows:</p>
<ul>
<li>respondent_id: Respondent ID</li>
<li>age: Age category</li>
<li>gender: Male or Female</li>
<li>education: Education level</li>
<li>employment: Employment status</li>
<li>marital_status: Marital status</li>
<li>fwb1_1 to fwb1_6: First six items with 1=Not at all to 5=Completely</li>
<li>fwb2_1 to fwb2_4: The last four items with 1=Never to 5=Always</li>
<li>raise2000: Confidence in ability to raise $2000 in 30 days</li>
<li>financial_knowledge: Overall financial knowledge (self-reported)</li>
<li>debt_collector: Contacted by a debt collector in past 12 months</li>
<li>hardship_food: Food didn‚Äôt last and didn‚Äôt have money to get more</li>
<li>hardship_doctor: Any household member couldn‚Äôt afford to see doctor or go to hospital</li>
</ul>
<p>As we are going to use the responses in this example, let‚Äôs save it as a separate dataset and then use the <code>describe</code> function from the <strong>psych</strong> package to examine the dataset:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="construct-validation.html#cb27-1" aria-hidden="true" tabindex="-1"></a>response <span class="ot">&lt;-</span> finance <span class="sc">%&gt;%</span></span>
<span id="cb27-2"><a href="construct-validation.html#cb27-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(dplyr<span class="sc">::</span><span class="fu">starts_with</span>(<span class="st">&quot;fwb&quot;</span>))</span>
<span id="cb27-3"><a href="construct-validation.html#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="construct-validation.html#cb27-4" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(response)</span></code></pre></div>
<table class=" lightable-paper lightable-hover table table-striped table-hover table-condensed" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
vars
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
range
</th>
<th style="text-align:right;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
fwb1_1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.89
</td>
<td style="text-align:right;">
1.24
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.020
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
3.08
</td>
<td style="text-align:right;">
1.12
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.018
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.68
</td>
<td style="text-align:right;">
1.20
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.019
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_4
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
3.14
</td>
<td style="text-align:right;">
1.05
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.017
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_5
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.86
</td>
<td style="text-align:right;">
1.25
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.020
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_6
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
3.24
</td>
<td style="text-align:right;">
1.14
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.018
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_1
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.48
</td>
<td style="text-align:right;">
1.20
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.019
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_2
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
3.27
</td>
<td style="text-align:right;">
1.27
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.020
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_3
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.21
</td>
<td style="text-align:right;">
1.15
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.019
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_4
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
3,822
</td>
<td style="text-align:right;">
2.82
</td>
<td style="text-align:right;">
1.14
</td>
<td style="text-align:right;">
-4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.018
</td>
</tr>
</tbody>
</table>
<p>The summary above shows that the minimum response value for the scale items is -4. The <a href="data_and_codes\cfpb_codebook.pdf">codebook</a> for this dataset shows that missing responses are coded as -1 and -4 in the dataset. So, we will have to change these values to NA.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="construct-validation.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Recode missing items</span></span>
<span id="cb28-2"><a href="construct-validation.html#cb28-2" aria-hidden="true" tabindex="-1"></a>response <span class="ot">&lt;-</span> <span class="fu">apply</span>(response, <span class="co"># data to apply the function</span></span>
<span id="cb28-3"><a href="construct-validation.html#cb28-3" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">2</span>, <span class="co"># 1 to apply to each row; 2 to apply to each column</span></span>
<span id="cb28-4"><a href="construct-validation.html#cb28-4" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">function</span>(x) <span class="fu">ifelse</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">4</span>), <span class="cn">NA</span>, x)) <span class="sc">%&gt;%</span></span>
<span id="cb28-5"><a href="construct-validation.html#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>()</span></code></pre></div>
<p>Now, we can review the cleaned dataset. First, we will review if the response options have been properly utilized in each item.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="construct-validation.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(response, <span class="dv">2</span>, table)</span></code></pre></div>
<pre><code>  fwb1_1 fwb1_2 fwb1_3 fwb1_4 fwb1_5 fwb1_6 fwb2_1 fwb2_2 fwb2_3 fwb2_4
1    671    382    634    269    605    237    894    367   1214    459
2    670    633   1178    617    892    688   1202    691   1294   1078
3   1272   1441   1139   1559   1236   1467   1001   1086    780   1285
4    797    983    478    998    572    750    415    866    320    648
5    406    376    387    372    509    674    304    804    207    345</code></pre>
<p>Next, we will visualize the data:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="construct-validation.html#cb31-1" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">introduce</span>(response)</span></code></pre></div>
<pre><code>  rows columns discrete_columns continuous_columns all_missing_columns
1 3822      10                0                 10                   0
  total_missing_values complete_rows total_observations memory_usage
1                   68          3811              38220       155832</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="construct-validation.html#cb33-1" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">plot_intro</span>(response)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons26-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="construct-validation.html#cb34-1" aria-hidden="true" tabindex="-1"></a>DataExplorer<span class="sc">::</span><span class="fu">plot_histogram</span>(response) </span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons26-2.png" width="768" style="display: block; margin: auto;" /></p>
<p>The dataset consists of 3822 rows (i.e., respondents) and 10 variables (i.e., FWB Scale Items). The response options are distributed nicely across the items, although some items such as fwb2_3 have a skewed distribution. To better understand the relationships among the items, we will also check the correlations. Since the items are polytomously scored, we will compute the inter-item correlations among the items using the <code>polychoric()</code> function from <strong>psych</strong> and then extract ‚Äúrho‚Äù (i.e., the correlation matrix of the items).</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="construct-validation.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the correlation matrix</span></span>
<span id="cb35-2"><a href="construct-validation.html#cb35-2" aria-hidden="true" tabindex="-1"></a>cormat <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">polychoric</span>(<span class="at">x =</span> response)<span class="sc">$</span>rho</span>
<span id="cb35-3"><a href="construct-validation.html#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="construct-validation.html#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the correlation matrix</span></span>
<span id="cb35-5"><a href="construct-validation.html#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cormat)</span></code></pre></div>
<table class="table table-striped table-condensed" style="font-size: 11px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
fwb1_1
</th>
<th style="text-align:right;">
fwb1_2
</th>
<th style="text-align:right;">
fwb1_3
</th>
<th style="text-align:right;">
fwb1_4
</th>
<th style="text-align:right;">
fwb1_5
</th>
<th style="text-align:right;">
fwb1_6
</th>
<th style="text-align:right;">
fwb2_1
</th>
<th style="text-align:right;">
fwb2_2
</th>
<th style="text-align:right;">
fwb2_3
</th>
<th style="text-align:right;">
fwb2_4
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
fwb1_1
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.727
</td>
<td style="text-align:right;">
-0.528
</td>
<td style="text-align:right;">
0.729
</td>
<td style="text-align:right;">
-0.519
</td>
<td style="text-align:right;">
-0.488
</td>
<td style="text-align:right;">
-0.632
</td>
<td style="text-align:right;">
0.711
</td>
<td style="text-align:right;">
-0.556
</td>
<td style="text-align:right;">
-0.500
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_2
</td>
<td style="text-align:right;">
0.727
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.538
</td>
<td style="text-align:right;">
0.742
</td>
<td style="text-align:right;">
-0.436
</td>
<td style="text-align:right;">
-0.506
</td>
<td style="text-align:right;">
-0.564
</td>
<td style="text-align:right;">
0.647
</td>
<td style="text-align:right;">
-0.486
</td>
<td style="text-align:right;">
-0.458
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_3
</td>
<td style="text-align:right;">
-0.528
</td>
<td style="text-align:right;">
-0.538
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.552
</td>
<td style="text-align:right;">
0.601
</td>
<td style="text-align:right;">
0.654
</td>
<td style="text-align:right;">
0.637
</td>
<td style="text-align:right;">
-0.556
</td>
<td style="text-align:right;">
0.553
</td>
<td style="text-align:right;">
0.581
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_4
</td>
<td style="text-align:right;">
0.729
</td>
<td style="text-align:right;">
0.742
</td>
<td style="text-align:right;">
-0.552
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.451
</td>
<td style="text-align:right;">
-0.491
</td>
<td style="text-align:right;">
-0.574
</td>
<td style="text-align:right;">
0.672
</td>
<td style="text-align:right;">
-0.538
</td>
<td style="text-align:right;">
-0.499
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_5
</td>
<td style="text-align:right;">
-0.519
</td>
<td style="text-align:right;">
-0.436
</td>
<td style="text-align:right;">
0.601
</td>
<td style="text-align:right;">
-0.451
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.522
</td>
<td style="text-align:right;">
0.574
</td>
<td style="text-align:right;">
-0.530
</td>
<td style="text-align:right;">
0.512
</td>
<td style="text-align:right;">
0.493
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb1_6
</td>
<td style="text-align:right;">
-0.488
</td>
<td style="text-align:right;">
-0.506
</td>
<td style="text-align:right;">
0.654
</td>
<td style="text-align:right;">
-0.491
</td>
<td style="text-align:right;">
0.522
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.545
</td>
<td style="text-align:right;">
-0.504
</td>
<td style="text-align:right;">
0.469
</td>
<td style="text-align:right;">
0.545
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_1
</td>
<td style="text-align:right;">
-0.632
</td>
<td style="text-align:right;">
-0.564
</td>
<td style="text-align:right;">
0.637
</td>
<td style="text-align:right;">
-0.574
</td>
<td style="text-align:right;">
0.574
</td>
<td style="text-align:right;">
0.545
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.689
</td>
<td style="text-align:right;">
0.687
</td>
<td style="text-align:right;">
0.643
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_2
</td>
<td style="text-align:right;">
0.711
</td>
<td style="text-align:right;">
0.647
</td>
<td style="text-align:right;">
-0.556
</td>
<td style="text-align:right;">
0.672
</td>
<td style="text-align:right;">
-0.530
</td>
<td style="text-align:right;">
-0.504
</td>
<td style="text-align:right;">
-0.689
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.621
</td>
<td style="text-align:right;">
-0.532
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_3
</td>
<td style="text-align:right;">
-0.556
</td>
<td style="text-align:right;">
-0.486
</td>
<td style="text-align:right;">
0.553
</td>
<td style="text-align:right;">
-0.538
</td>
<td style="text-align:right;">
0.512
</td>
<td style="text-align:right;">
0.469
</td>
<td style="text-align:right;">
0.687
</td>
<td style="text-align:right;">
-0.621
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.596
</td>
</tr>
<tr>
<td style="text-align:left;">
fwb2_4
</td>
<td style="text-align:right;">
-0.500
</td>
<td style="text-align:right;">
-0.458
</td>
<td style="text-align:right;">
0.581
</td>
<td style="text-align:right;">
-0.499
</td>
<td style="text-align:right;">
0.493
</td>
<td style="text-align:right;">
0.545
</td>
<td style="text-align:right;">
0.643
</td>
<td style="text-align:right;">
-0.532
</td>
<td style="text-align:right;">
0.596
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>The correlation matrix above shows negative correlations among the items due to positive/negative wording of the items in the scale. To put the items in the same direction, we will reverse-recode the negatively-worded items in the scale.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="construct-validation.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First, let&#39;s save the original variable names</span></span>
<span id="cb36-2"><a href="construct-validation.html#cb36-2" aria-hidden="true" tabindex="-1"></a>names_fwb <span class="ot">&lt;-</span> <span class="fu">colnames</span>(response)</span>
<span id="cb36-3"><a href="construct-validation.html#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="construct-validation.html#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reverse code negatively-worded items 3,5,6,7,9, and 10</span></span>
<span id="cb36-5"><a href="construct-validation.html#cb36-5" aria-hidden="true" tabindex="-1"></a>keys <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb36-6"><a href="construct-validation.html#cb36-6" aria-hidden="true" tabindex="-1"></a>response_final <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">reverse.code</span>(keys, </span>
<span id="cb36-7"><a href="construct-validation.html#cb36-7" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">items =</span> response,</span>
<span id="cb36-8"><a href="construct-validation.html#cb36-8" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">mini =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>),</span>
<span id="cb36-9"><a href="construct-validation.html#cb36-9" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">maxi =</span> <span class="fu">rep</span>(<span class="dv">5</span>, <span class="dv">10</span>))</span>
<span id="cb36-10"><a href="construct-validation.html#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="construct-validation.html#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># View the recoded dataset</span></span>
<span id="cb36-12"><a href="construct-validation.html#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(response_final)</span></code></pre></div>
<pre><code>     fwb1_1 fwb1_2 fwb1_3- fwb1_4 fwb1_5- fwb1_6- fwb2_1- fwb2_2 fwb2_3-
[1,]      2      2       3      3       3       2       4      2       4
[2,]      3      3       3      3       3       3       3      3       3
[3,]      3      3       3      3       3       3       3      3       3
[4,]      3      3       3      3       3       3       3      3       3
[5,]      5      1       5      1       5       5       4      5       4
[6,]      1      3       4      3       3       3       3      2       5
     fwb2_4-
[1,]       3
[2,]       3
[3,]       3
[4,]       3
[5,]       4
[6,]       2</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="construct-validation.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now let&#39;s change the names to the original names to avoid &quot;-&quot; added to the names</span></span>
<span id="cb38-2"><a href="construct-validation.html#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(response_final) <span class="ot">&lt;-</span> names_fwb</span>
<span id="cb38-3"><a href="construct-validation.html#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="construct-validation.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, recalculate the correlation matrix</span></span>
<span id="cb38-5"><a href="construct-validation.html#cb38-5" aria-hidden="true" tabindex="-1"></a>cormat <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">polychoric</span>(<span class="at">x =</span> response_final)<span class="sc">$</span>rho</span></code></pre></div>
<p>Next, we will check the associations among the items in the new dataset using a correlation matrix plot to confirm that the items are all positively correlated.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="construct-validation.html#cb39-1" aria-hidden="true" tabindex="-1"></a>ggcorrplot<span class="sc">::</span><span class="fu">ggcorrplot</span>(<span class="at">corr =</span> cormat, <span class="co"># correlation matrix</span></span>
<span id="cb39-2"><a href="construct-validation.html#cb39-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">type =</span> <span class="st">&quot;lower&quot;</span>, <span class="co"># print only the lower part of the correlation matrix</span></span>
<span id="cb39-3"><a href="construct-validation.html#cb39-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">hc.order =</span> <span class="cn">TRUE</span>, <span class="co"># hierarchical clustering</span></span>
<span id="cb39-4"><a href="construct-validation.html#cb39-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">show.diag =</span> <span class="cn">TRUE</span>, <span class="co"># show the diagonal values of 1</span></span>
<span id="cb39-5"><a href="construct-validation.html#cb39-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">lab =</span> <span class="cn">TRUE</span>, <span class="co"># add correlation values as labels</span></span>
<span id="cb39-6"><a href="construct-validation.html#cb39-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">lab_size =</span> <span class="dv">3</span>) <span class="co"># Size of the labels</span></span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons30-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>The correlation matrix plot confirms that all the items are now positively correlated with each other. We can begin to analyze the items. Note that if there is any item wording effect present in the data, reverse-coding the items would not necessarily fix the problem. We will see a good example of this situation in the following analyses.</p>
</div>
<div id="parallel-analysis" class="section level4 unnumbered hasAnchor">
<h4>Parallel Analysis<a href="construct-validation.html#parallel-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Parallel analysis compares the magnitude or size of eigenvalues generated from random data against the eigenvalues from the sample correlation matrix generated by the model. The main idea is that meaningful associations in the data should yield eigenvalues larger than would be expected by change.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="construct-validation.html#cb40-1" aria-hidden="true" tabindex="-1"></a>parallel.test <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa.parallel</span>(<span class="at">x =</span> response_final, </span>
<span id="cb40-2"><a href="construct-validation.html#cb40-2" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">fm=</span><span class="st">&quot;ml&quot;</span>, <span class="co"># maximum likelihood</span></span>
<span id="cb40-3"><a href="construct-validation.html#cb40-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">fa=</span><span class="st">&quot;fa&quot;</span>, <span class="co"># principal axis factor analysis</span></span>
<span id="cb40-4"><a href="construct-validation.html#cb40-4" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">cor=</span><span class="st">&quot;poly&quot;</span>, <span class="co"># use polychoric correlations</span></span>
<span id="cb40-5"><a href="construct-validation.html#cb40-5" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">n.iter =</span> <span class="dv">20</span>, <span class="co"># number of iterations</span></span>
<span id="cb40-6"><a href="construct-validation.html#cb40-6" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">error.bars =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons31-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre><code>Parallel analysis suggests that the number of factors =  3  and the number of components =  NA </code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="construct-validation.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(parallel.test)</span></code></pre></div>
<pre><code>Call: psych::fa.parallel(x = response_final, fm = &quot;ml&quot;, fa = &quot;fa&quot;, 
    n.iter = 20, error.bars = TRUE, cor = &quot;poly&quot;)
Parallel analysis suggests that the number of factors =  3  and the number of components =  NA 

 Eigen Values of 

 eigen values of factors
 [1]  5.71  0.48  0.18  0.01 -0.05 -0.08 -0.09 -0.13 -0.15 -0.17

 eigen values of simulated factors
 [1]  0.59  0.06  0.04  0.03  0.02  0.00 -0.01 -0.03 -0.04 -0.06

 eigen values of components 
 [1] 6.13 0.91 0.63 0.52 0.38 0.34 0.32 0.28 0.25 0.24

 eigen values of simulated components
[1] NA</code></pre>
<p>The results of our parallel analysis suggest that there are possibly three factors underlying the responses to the FWB Scale. We can increase the number of iterations and try again, though it is very like that the result will remain the same.</p>
</div>
<div id="confirmatory-factor-analysis" class="section level4 unnumbered hasAnchor">
<h4>Confirmatory Factor Analysis<a href="construct-validation.html#confirmatory-factor-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In CFA, the researcher must specify the expected relationships between indicators (i.e., observed variables) and latent factors. In other words, one must have an explicit account of what factor(s) underlie each item. In this example, we will evaluate two scenarios about the FCW Scale: two-factor structure (separate dimensions based on positive and negative wording), and a bi-factor structure with a general dimension and separate dimensions based on positive and negative wording.</p>
<p>We will use the <strong>lavaan</strong> package <span class="citation">(<a href="#ref-R-lavaan" role="doc-biblioref">Rosseel et al., 2022</a>)</span> (see <a href="https://lavaan.ugent.be/" class="uri">https://lavaan.ugent.be/</a> for more information on the package) to estimate our CFA models. To understand how to set up a CFA model in <strong>lavaan</strong>, we can use the following table on the <strong>lavaan</strong> website (<a href="https://lavaan.ugent.be/tutorial/syntax1.html" class="uri">https://lavaan.ugent.be/tutorial/syntax1.html</a>).</p>
<table class="table table-striped table-hover" style>
<thead>
<tr>
<th style="text-align:left;">
Formula Type
</th>
<th style="text-align:left;">
lavaan Operator
</th>
<th style="text-align:left;">
Meaning
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Latent variable
</td>
<td style="text-align:left;">
=~
</td>
<td style="text-align:left;">
is measured by
</td>
</tr>
<tr>
<td style="text-align:left;">
Regression
</td>
<td style="text-align:left;">
~
</td>
<td style="text-align:left;">
is regressed on
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual co(variance)
</td>
<td style="text-align:left;">
~~
</td>
<td style="text-align:left;">
is correlated with
</td>
</tr>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:left;">
intercept
</td>
</tr>
</tbody>
</table>
<p>The format used in <strong>lavaan</strong> is fairly simple, and resembles a series of linear models, written over several lines. In the model below, there are two latent variables, pw and nw, referring to the positive wording and negative wording. The latent variable names are followed by =~ which means ‚Äúis manifested by‚Äù, and then the observed variables are listed, separated by the ‚Äú+‚Äù sign.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="construct-validation.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a two-factor model</span></span>
<span id="cb44-2"><a href="construct-validation.html#cb44-2" aria-hidden="true" tabindex="-1"></a>model.two <span class="ot">&lt;-</span> <span class="st">&#39;# Define factors</span></span>
<span id="cb44-3"><a href="construct-validation.html#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="st">              pw =~ fwb1_3 + fwb2_4 + fwb2_1 + fwb1_5 + fwb1_6 + fwb2_3</span></span>
<span id="cb44-4"><a href="construct-validation.html#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="st">              nw =~ fwb1_2 + fwb1_4 + fwb1_1 + fwb2_2</span></span>
<span id="cb44-5"><a href="construct-validation.html#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb44-6"><a href="construct-validation.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="st">              # Variances and covariances</span></span>
<span id="cb44-7"><a href="construct-validation.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="st">              pw ~~ pw</span></span>
<span id="cb44-8"><a href="construct-validation.html#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="st">              nw ~~ nw</span></span>
<span id="cb44-9"><a href="construct-validation.html#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="st">              pw ~~ nw&#39;</span></span></code></pre></div>
<p>Using the model above will give us factor loadings for the item, variances for the latent factors, and the covariance or correlation between the two factors we defined. Alternatively, we could use <code>pw ~~ 0*nw</code> to force orthogonal (uncorrelated) factors if our hypothesis about the underlying factor structure assumed uncorrelated factors. Also, this model will fix the factor loading for the first item associated with each factor to 1. We could free these items by fixing the variance of the factors to 1 to maintain the same degrees of freedom.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="construct-validation.html#cb45-1" aria-hidden="true" tabindex="-1"></a>model.two <span class="ot">&lt;-</span> <span class="st">&#39;# Define factors</span></span>
<span id="cb45-2"><a href="construct-validation.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="st">              pw =~ NA*fwb1_3 + fwb2_4 + fwb2_1 + fwb1_5 + fwb1_6 + fwb2_3</span></span>
<span id="cb45-3"><a href="construct-validation.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="st">              nw =~ NA*fwb1_2 + fwb1_4 + fwb1_1 + fwb2_2</span></span>
<span id="cb45-4"><a href="construct-validation.html#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb45-5"><a href="construct-validation.html#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="st">              # Variances and covariances</span></span>
<span id="cb45-6"><a href="construct-validation.html#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="st">              pw ~~ 1*pw</span></span>
<span id="cb45-7"><a href="construct-validation.html#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="st">              nw ~~ 1*nw</span></span>
<span id="cb45-8"><a href="construct-validation.html#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="st">              pw ~~ nw&#39;</span></span></code></pre></div>
<p>Once a model is defined properly, it can be used within the <code>cfa</code> function to fit the model to the data. In the following example, we will use <code>estimator = "WLSMV"</code> because our items are polytomous and this particular estimator is designed to deal with ordinal or categorical variables that may not necessarily have a normal distribution.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="construct-validation.html#cb46-1" aria-hidden="true" tabindex="-1"></a>cfa.wlsmv <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">cfa</span>(model.two, <span class="at">data =</span> response_final, <span class="at">estimator =</span> <span class="st">&quot;WLSMV&quot;</span>)</span></code></pre></div>
<p>Once the model has been fitted, the <code>summary()</code> function provides a nice summary of the fitted model. To better interpret the factor loadings, we request the standardized solutions by using <code>standardized=TRUE</code>.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="construct-validation.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cfa.wlsmv, <span class="at">fit.measures=</span><span class="cn">TRUE</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>lavaan 0.6-12 ended normally after 30 iterations

  Estimator                                       DWLS
  Optimization method                           NLMINB
  Number of model parameters                        21

                                                  Used       Total
  Number of observations                          3811        3822

Model Test User Model:
                                              Standard      Robust
  Test Statistic                               164.740     602.565
  Degrees of freedom                                34          34
  P-value (Chi-square)                           0.000       0.000
  Scaling correction factor                                  0.276
  Shift parameter                                            5.125
    simple second-order correction                                

Model Test Baseline Model:

  Test statistic                             38152.934   13355.485
  Degrees of freedom                                45          45
  P-value                                        0.000       0.000
  Scaling correction factor                                  2.863

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.997       0.957
  Tucker-Lewis Index (TLI)                       0.995       0.943
                                                                  
  Robust Comparative Fit Index (CFI)                            NA
  Robust Tucker-Lewis Index (TLI)                               NA

Root Mean Square Error of Approximation:

  RMSEA                                          0.032       0.066
  90 Percent confidence interval - lower         0.027       0.062
  90 Percent confidence interval - upper         0.037       0.071
  P-value RMSEA &lt;= 0.05                          1.000       0.000
                                                                  
  Robust RMSEA                                                  NA
  90 Percent confidence interval - lower                        NA
  90 Percent confidence interval - upper                        NA

Standardized Root Mean Square Residual:

  SRMR                                           0.031       0.031

Parameter Estimates:

  Standard errors                           Robust.sem
  Information                                 Expected
  Information saturated (h1) model        Unstructured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  pw =~                                                                 
    fwb1_3            1.000                               0.899    0.759
    fwb2_4            0.882    0.022   39.604    0.000    0.793    0.705
    fwb2_1            1.078    0.023   46.925    0.000    0.970    0.815
    fwb1_5            0.904    0.028   32.685    0.000    0.813    0.656
    fwb1_6            0.849    0.020   41.722    0.000    0.763    0.677
    fwb2_3            0.903    0.024   38.403    0.000    0.812    0.712
  nw =~                                                                 
    fwb1_2            1.000                               0.850    0.773
    fwb1_4            0.967    0.019   52.182    0.000    0.822    0.794
    fwb1_1            1.184    0.022   54.041    0.000    1.007    0.821
    fwb2_2            1.211    0.024   50.816    0.000    1.030    0.824

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  pw ~~                                                                 
    nw                0.636    0.021   30.139    0.000    0.832    0.832

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    pw                0.809    0.030   26.932    0.000    1.000    1.000
    nw                0.723    0.025   29.047    0.000    1.000    1.000
   .fwb1_3            0.596    0.022   27.211    0.000    0.596    0.424
   .fwb2_4            0.637    0.022   28.861    0.000    0.637    0.503
   .fwb2_1            0.474    0.019   25.247    0.000    0.474    0.335
   .fwb1_5            0.874    0.032   26.966    0.000    0.874    0.569
   .fwb1_6            0.690    0.023   29.956    0.000    0.690    0.542
   .fwb2_3            0.640    0.021   31.175    0.000    0.640    0.493
   .fwb1_2            0.488    0.016   29.619    0.000    0.488    0.403
   .fwb1_4            0.397    0.015   25.735    0.000    0.397    0.370
   .fwb1_1            0.490    0.021   23.881    0.000    0.490    0.326
   .fwb2_2            0.500    0.022   23.052    0.000    0.500    0.320</code></pre>
<p>To evaluate the model fit, we will use <span class="citation">Hu &amp; Bentler (<a href="#ref-hu1999cutoff" role="doc-biblioref">1999</a>)</span>‚Äôs guidelines for model fit indices: (1) Comparative fit index (CFI) &gt; .95; Tucker-Lewis index (TLI) &gt; .95; and root mean square error of approximation (RMSEA) &lt; .06. The output shows that the model fits the data very nicely!</p>
<p>In the output, the columns, <code>Std.lv</code> and <code>Std.all</code>, correspond to slightly different solutions. The <code>Std.all</code> solution standardizes the factor loadings by the standard deviation of both the predictor (the factor, X) and the outcome (the item, Y). In the variance standardization method <code>Std.lv</code>, we only standardize by the predictor (the factor, X). Comparing the two solutions, the loadings and variance of the factors are different but the residual variances are the same.</p>
<p>Using the <code>semPaths</code> function from the <strong>semPlot</strong> package, we can also visualize the model by creating a path diagram:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="construct-validation.html#cb49-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(cfa.wlsmv, <span class="st">&quot;std&quot;</span>) <span class="co"># &quot;std&quot; gives standardized loadings</span></span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons36-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Let‚Äôs also run the same model with robust maximum likelihood (known as MLR estimator) and check out the results.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="construct-validation.html#cb50-1" aria-hidden="true" tabindex="-1"></a>cfa.mlr <span class="ot">&lt;-</span> lavaan<span class="sc">::</span><span class="fu">cfa</span>(model.two, <span class="at">data =</span> response_final, <span class="at">estimator =</span> <span class="st">&quot;MLR&quot;</span>)</span>
<span id="cb50-2"><a href="construct-validation.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cfa.mlr, <span class="at">fit.measures=</span><span class="cn">TRUE</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>lavaan 0.6-12 ended normally after 25 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                        21

                                                  Used       Total
  Number of observations                          3811        3822

Model Test User Model:
                                              Standard      Robust
  Test Statistic                               827.665     650.309
  Degrees of freedom                                34          34
  P-value (Chi-square)                           0.000       0.000
  Scaling correction factor                                  1.273
    Yuan-Bentler correction (Mplus variant)                       

Model Test Baseline Model:

  Test statistic                             20848.665   14266.368
  Degrees of freedom                                45          45
  P-value                                        0.000       0.000
  Scaling correction factor                                  1.461

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.962       0.957
  Tucker-Lewis Index (TLI)                       0.950       0.943
                                                                  
  Robust Comparative Fit Index (CFI)                         0.962
  Robust Tucker-Lewis Index (TLI)                            0.950

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)             -49717.248  -49717.248
  Scaling correction factor                                  1.402
      for the MLR correction                                      
  Loglikelihood unrestricted model (H1)     -49303.416  -49303.416
  Scaling correction factor                                  1.322
      for the MLR correction                                      
                                                                  
  Akaike (AIC)                               99476.497   99476.497
  Bayesian (BIC)                             99607.656   99607.656
  Sample-size adjusted Bayesian (BIC)        99540.927   99540.927

Root Mean Square Error of Approximation:

  RMSEA                                          0.078       0.069
  90 Percent confidence interval - lower         0.074       0.065
  90 Percent confidence interval - upper         0.083       0.073
  P-value RMSEA &lt;= 0.05                          0.000       0.000
                                                                  
  Robust RMSEA                                               0.078
  90 Percent confidence interval - lower                     0.073
  90 Percent confidence interval - upper                     0.083

Standardized Root Mean Square Residual:

  SRMR                                           0.033       0.033

Parameter Estimates:

  Standard errors                             Sandwich
  Information bread                           Observed
  Observed information based on                Hessian

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  pw =~                                                                 
    fwb1_3            1.000                               0.899    0.758
    fwb2_4            0.894    0.022   40.068    0.000    0.804    0.715
    fwb2_1            1.068    0.024   44.145    0.000    0.960    0.808
    fwb1_5            0.904    0.026   34.175    0.000    0.813    0.656
    fwb1_6            0.848    0.019   44.935    0.000    0.762    0.676
    fwb2_3            0.902    0.025   36.262    0.000    0.811    0.712
  nw =~                                                                 
    fwb1_2            1.000                               0.873    0.793
    fwb1_4            0.957    0.017   56.853    0.000    0.835    0.806
    fwb1_1            1.165    0.020   56.982    0.000    1.017    0.830
    fwb2_2            1.132    0.024   48.177    0.000    0.988    0.791

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  pw ~~                                                                 
    nw                0.651    0.021   31.578    0.000    0.829    0.829

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    pw                0.808    0.030   26.549    0.000    1.000    1.000
    nw                0.762    0.025   29.939    0.000    1.000    1.000
   .fwb1_3            0.597    0.022   26.857    0.000    0.597    0.425
   .fwb2_4            0.619    0.021   29.059    0.000    0.619    0.489
   .fwb2_1            0.491    0.019   25.906    0.000    0.491    0.348
   .fwb1_5            0.873    0.032   27.445    0.000    0.873    0.569
   .fwb1_6            0.691    0.023   30.000    0.000    0.691    0.543
   .fwb2_3            0.642    0.021   30.895    0.000    0.642    0.494
   .fwb1_2            0.449    0.016   27.664    0.000    0.449    0.371
   .fwb1_4            0.375    0.015   25.055    0.000    0.375    0.350
   .fwb1_1            0.468    0.020   23.986    0.000    0.468    0.312
   .fwb2_2            0.584    0.021   27.271    0.000    0.584    0.374</code></pre>
<p>The results show that the estimated values for factor loadings, residuals, correlation between the factors have changed slightly when we used the MLR estimator. Compared with the WLSMV solution, the model fit indices are slightly worse, indicating that WLSMV provided a better solution. This is not necessarily surprising given that the items in the FWB scale are all polytomous.</p>
<p>In addition to the two-factor solution, we will also try the bi-factor model. We can achieve this either manually setting up the model with uncorrelated factors or using <code>orthogonal=TRUE</code> in the <code>cfa</code> function. We will use the easy way to set up our model. <code>std.lv=TRUE</code> is also a shortcut to get the factor variances fixed to 1 while getting free estimates of factor loadings for all items.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="construct-validation.html#cb52-1" aria-hidden="true" tabindex="-1"></a>bi.model <span class="ot">&lt;-</span> <span class="st">&#39;# Define factors</span></span>
<span id="cb52-2"><a href="construct-validation.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="st">             g =~ fwb1_3 + fwb2_4 + fwb2_1 + fwb1_5 + fwb1_6 + fwb2_3 + fwb1_2 + fwb1_4 + fwb1_1 + fwb2_2</span></span>
<span id="cb52-3"><a href="construct-validation.html#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="st">             pw =~ fwb1_3 + fwb2_4 + fwb2_1 + fwb1_5 + fwb1_6 + fwb2_3</span></span>
<span id="cb52-4"><a href="construct-validation.html#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="st">             nw =~ fwb1_2 + fwb1_4 + fwb1_1 + fwb2_2&#39;</span></span>
<span id="cb52-5"><a href="construct-validation.html#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="construct-validation.html#cb52-6" aria-hidden="true" tabindex="-1"></a>bifactor.wlsmv <span class="ot">&lt;-</span> <span class="fu">cfa</span>(bi.model, <span class="at">data=</span>response_final, <span class="at">estimator =</span> <span class="st">&quot;WLSMV&quot;</span>, </span>
<span id="cb52-7"><a href="construct-validation.html#cb52-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">orthogonal=</span><span class="cn">TRUE</span>, <span class="at">std.lv=</span><span class="cn">TRUE</span>)</span>
<span id="cb52-8"><a href="construct-validation.html#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bifactor.wlsmv, <span class="at">fit.measures=</span><span class="cn">TRUE</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>lavaan 0.6-12 ended normally after 69 iterations

  Estimator                                       DWLS
  Optimization method                           NLMINB
  Number of model parameters                        30

                                                  Used       Total
  Number of observations                          3811        3822

Model Test User Model:
                                              Standard      Robust
  Test Statistic                                41.084     194.922
  Degrees of freedom                                25          25
  P-value (Chi-square)                           0.022       0.000
  Scaling correction factor                                  0.213
  Shift parameter                                            2.283
    simple second-order correction                                

Model Test Baseline Model:

  Test statistic                             38152.934   13355.485
  Degrees of freedom                                45          45
  P-value                                        0.000       0.000
  Scaling correction factor                                  2.863

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000       0.987
  Tucker-Lewis Index (TLI)                       0.999       0.977
                                                                  
  Robust Comparative Fit Index (CFI)                            NA
  Robust Tucker-Lewis Index (TLI)                               NA

Root Mean Square Error of Approximation:

  RMSEA                                          0.013       0.042
  90 Percent confidence interval - lower         0.005       0.037
  90 Percent confidence interval - upper         0.020       0.048
  P-value RMSEA &lt;= 0.05                          1.000       0.989
                                                                  
  Robust RMSEA                                                  NA
  90 Percent confidence interval - lower                        NA
  90 Percent confidence interval - upper                        NA

Standardized Root Mean Square Residual:

  SRMR                                           0.016       0.016

Parameter Estimates:

  Standard errors                           Robust.sem
  Information                                 Expected
  Information saturated (h1) model        Unstructured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  g =~                                                                  
    fwb1_3            0.883    0.019   47.545    0.000    0.883    0.745
    fwb2_4            0.789    0.017   46.473    0.000    0.789    0.701
    fwb2_1            0.994    0.016   61.613    0.000    0.994    0.836
    fwb1_5            0.799    0.022   35.622    0.000    0.799    0.645
    fwb1_6            0.750    0.019   38.577    0.000    0.750    0.665
    fwb2_3            0.838    0.018   45.852    0.000    0.838    0.736
    fwb1_2            0.684    0.018   37.475    0.000    0.684    0.622
    fwb1_4            0.669    0.018   38.133    0.000    0.669    0.645
    fwb1_1            0.828    0.019   44.188    0.000    0.828    0.675
    fwb2_2            0.899    0.018   50.125    0.000    0.899    0.720
  pw =~                                                                 
    fwb1_3            0.344    0.037    9.383    0.000    0.344    0.291
    fwb2_4            0.048    0.029    1.636    0.102    0.048    0.043
    fwb2_1           -0.166    0.038   -4.372    0.000   -0.166   -0.139
    fwb1_5            0.196    0.036    5.508    0.000    0.196    0.158
    fwb1_6            0.416    0.037   11.100    0.000    0.416    0.369
    fwb2_3           -0.197    0.031   -6.297    0.000   -0.197   -0.172
  nw =~                                                                 
    fwb1_2            0.578    0.022   25.766    0.000    0.578    0.525
    fwb1_4            0.522    0.021   24.723    0.000    0.522    0.504
    fwb1_1            0.591    0.024   24.567    0.000    0.591    0.482
    fwb2_2            0.388    0.026   14.912    0.000    0.388    0.310

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  g ~~                                                                  
    pw                0.000                               0.000    0.000
    nw                0.000                               0.000    0.000
  pw ~~                                                                 
    nw                0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .fwb1_3            0.507    0.027   19.105    0.000    0.507    0.361
   .fwb2_4            0.641    0.022   29.182    0.000    0.641    0.506
   .fwb2_1            0.398    0.026   15.129    0.000    0.398    0.281
   .fwb1_5            0.857    0.032   26.963    0.000    0.857    0.559
   .fwb1_6            0.537    0.031   17.492    0.000    0.537    0.422
   .fwb2_3            0.558    0.025   22.324    0.000    0.558    0.429
   .fwb1_2            0.409    0.018   22.409    0.000    0.409    0.338
   .fwb1_4            0.354    0.016   22.204    0.000    0.354    0.330
   .fwb1_1            0.468    0.021   22.428    0.000    0.468    0.311
   .fwb2_2            0.603    0.020   30.476    0.000    0.603    0.386
    g                 1.000                               1.000    1.000
    pw                1.000                               1.000    1.000
    nw                1.000                               1.000    1.000</code></pre>
<p>Let‚Äôs also see the results visually:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="construct-validation.html#cb54-1" aria-hidden="true" tabindex="-1"></a>semPlot<span class="sc">::</span><span class="fu">semPaths</span>(bifactor.wlsmv, <span class="st">&quot;std&quot;</span>) <span class="co"># &quot;std&quot; gives standardized loadings</span></span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons39-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>The bi-factor model also seems to fit the data nicely (even slightly better than the two-factor model) but we see that some factor loadings are negative. This is probably the strength of the general (g) factor we defined. This factor absorbs most of the variance in the items, leaving only small variance to be explained by the pw and nw factors. At this point, we may believe that there is an overall factor of financial well-being but it is hard to extract in a unidimensional model due to item wording effects. Using the bi-factor model could possibly partial out the variance due to item wording while accounting for a large amount of variance available in the items.</p>
<p>We can run a quick model comparison using the <code>anova</code> function.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="construct-validation.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(cfa.wlsmv, bifactor.wlsmv)</span></code></pre></div>
<pre><code>Scaled Chi-Squared Difference Test (method = &quot;satorra.2000&quot;)

lavaan NOTE:
    The &quot;Chisq&quot; column contains standard test statistics, not the
    robust test that should be reported per model. A robust difference
    test is a function of two standard (not robust) statistics.
 
               Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)    
bifactor.wlsmv 25          41.1                                  
cfa.wlsmv      34         164.7        322       9     &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="principal-component-analysis-pca" class="section level4 hasAnchor" number="2.1.0.1">
<h4><span class="header-section-number">2.1.0.1</span> Principal Component Analysis (PCA)<a href="construct-validation.html#principal-component-analysis-pca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We will finish this example with a small demonstration of how principal component analysis works. This time, we will use the last five variables in the finance dataset:</p>
<ul>
<li>raise2000: Confidence in ability to raise $2000 in 30 days (1 to 4, higher values indicate higher confidence)</li>
<li>financial_knowledge: Overall financial knowledge (1 to 7, higher alues indicate higher knowledge)</li>
<li>debt_collector: Contacted by a debt collector in past 12 months (1=yes, 0=no)</li>
<li>hardship_food: Food didn‚Äôt last and didn‚Äôt have money to get more (1=never, 2=sometimes, 3=often)</li>
<li>hardship_doctor: Any household member couldn‚Äôt afford to see doctor or go to hospital (1=never, 2=sometimes, 3=often)</li>
</ul>
<p>Our goal is to <em>reduce</em> the number of these variables through PCA (rather than creating a latent variable based on these variables). After creating a separate dataset with these variables, we will deal with missing values. For each variable, -1 refers to ‚ÄúRefused to respond‚Äù and 8 refers to ‚ÄúNot sure‚Äù. So, we will recode these values as NA.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="construct-validation.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the variables of interest</span></span>
<span id="cb57-2"><a href="construct-validation.html#cb57-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> finance <span class="sc">%&gt;%</span></span>
<span id="cb57-3"><a href="construct-validation.html#cb57-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(raise2000, financial_knowledge, debt_collector, </span>
<span id="cb57-4"><a href="construct-validation.html#cb57-4" aria-hidden="true" tabindex="-1"></a>                hardship_food, hardship_doctor)</span>
<span id="cb57-5"><a href="construct-validation.html#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="construct-validation.html#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Recode missing items</span></span>
<span id="cb57-7"><a href="construct-validation.html#cb57-7" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">apply</span>(data, <span class="co"># data to apply the function</span></span>
<span id="cb57-8"><a href="construct-validation.html#cb57-8" aria-hidden="true" tabindex="-1"></a>              <span class="dv">2</span>, <span class="co"># 1 to apply to each row; 2 to apply to each column</span></span>
<span id="cb57-9"><a href="construct-validation.html#cb57-9" aria-hidden="true" tabindex="-1"></a>              <span class="cf">function</span>(x) <span class="fu">ifelse</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">8</span>), <span class="cn">NA</span>, x)) <span class="sc">%&gt;%</span></span>
<span id="cb57-10"><a href="construct-validation.html#cb57-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>()</span></code></pre></div>
<p>Next, we will use the <code>principal</code> function to perform PCA and extract one component.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="construct-validation.html#cb58-1" aria-hidden="true" tabindex="-1"></a>pca_results1 <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(</span>
<span id="cb58-2"><a href="construct-validation.html#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> data, </span>
<span id="cb58-3"><a href="construct-validation.html#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfactors =</span> <span class="dv">1</span>, <span class="co"># Number of components to extract</span></span>
<span id="cb58-4"><a href="construct-validation.html#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">rotate=</span><span class="st">&quot;varimax&quot;</span>,</span>
<span id="cb58-5"><a href="construct-validation.html#cb58-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cor =</span> <span class="st">&quot;mixed&quot;</span> <span class="co"># for a mixture of tetrachorics, polychorics, and so on</span></span>
<span id="cb58-6"><a href="construct-validation.html#cb58-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb58-7"><a href="construct-validation.html#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="construct-validation.html#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pca_results1)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = data, nfactors = 1, rotate = &quot;varimax&quot;, 
    cor = &quot;mixed&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      PC1   h2   u2 com
raise2000           -0.87 0.75 0.25   1
financial_knowledge -0.47 0.22 0.78   1
debt_collector       0.77 0.59 0.41   1
hardship_food        0.88 0.78 0.22   1
hardship_doctor      0.80 0.64 0.36   1

                PC1
SS loadings    2.98
Proportion Var 0.60

Mean item complexity =  1
Test of the hypothesis that 1 component is sufficient.

The root mean square of the residuals (RMSR) is  0.11 
 with the empirical chi square  911  with prob &lt;  1.1e-194 

Fit based upon off diagonal values = 0.95</code></pre>
<p>The output shows that one component explains 60% of the total variance. Now, let‚Äôs also try two components and see if this increases the amount of explained variance:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="construct-validation.html#cb60-1" aria-hidden="true" tabindex="-1"></a>pca_results2a <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(</span>
<span id="cb60-2"><a href="construct-validation.html#cb60-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> data, </span>
<span id="cb60-3"><a href="construct-validation.html#cb60-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfactors =</span> <span class="dv">2</span>, </span>
<span id="cb60-4"><a href="construct-validation.html#cb60-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">rotate=</span><span class="st">&quot;varimax&quot;</span>,</span>
<span id="cb60-5"><a href="construct-validation.html#cb60-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cor =</span> <span class="st">&quot;mixed&quot;</span></span>
<span id="cb60-6"><a href="construct-validation.html#cb60-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb60-7"><a href="construct-validation.html#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="construct-validation.html#cb60-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pca_results2a)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = data, nfactors = 2, rotate = &quot;varimax&quot;, 
    cor = &quot;mixed&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      RC1   RC2   h2    u2 com
raise2000           -0.79  0.37 0.76 0.239 1.4
financial_knowledge -0.14  0.98 0.97 0.026 1.0
debt_collector       0.77 -0.12 0.61 0.387 1.0
hardship_food        0.89 -0.15 0.81 0.192 1.1
hardship_doctor      0.84 -0.03 0.71 0.290 1.0

                       RC1  RC2
SS loadings           2.74 1.13
Proportion Var        0.55 0.23
Cumulative Var        0.55 0.77
Proportion Explained  0.71 0.29
Cumulative Proportion 0.71 1.00

Mean item complexity =  1.1
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.09 
 with the empirical chi square  573  with prob &lt;  1.5e-126 

Fit based upon off diagonal values = 0.97</code></pre>
<p>The two components seem to explain almost 77% of the total variance. This is great because now we can use these two components instead of all five variables if we want to include them in a predictive model (leading to higher model parsimony). Let‚Äôs also see the plot for this solution:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="construct-validation.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(pca_results2a,</span>
<span id="cb62-2"><a href="construct-validation.html#cb62-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">&quot;PCA with Financial Variables: Varimax Rotation&quot;</span>)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons44-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Let‚Äôs also try to estimate the same model with oblique rotation.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="construct-validation.html#cb63-1" aria-hidden="true" tabindex="-1"></a>pca_results2b <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">principal</span>(</span>
<span id="cb63-2"><a href="construct-validation.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> data, </span>
<span id="cb63-3"><a href="construct-validation.html#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfactors =</span> <span class="dv">2</span>, </span>
<span id="cb63-4"><a href="construct-validation.html#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">rotate=</span><span class="st">&quot;promax&quot;</span>,</span>
<span id="cb63-5"><a href="construct-validation.html#cb63-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cor =</span> <span class="st">&quot;mixed&quot;</span></span>
<span id="cb63-6"><a href="construct-validation.html#cb63-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb63-7"><a href="construct-validation.html#cb63-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-8"><a href="construct-validation.html#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pca_results2b)</span></code></pre></div>
<pre><code>Principal Components Analysis
Call: psych::principal(r = data, nfactors = 2, rotate = &quot;promax&quot;, cor = &quot;mixed&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
                      RC1  RC2   h2    u2 com
raise2000           -0.77 0.23 0.76 0.239 1.2
financial_knowledge  0.02 0.99 0.97 0.026 1.0
debt_collector       0.79 0.03 0.61 0.387 1.0
hardship_food        0.91 0.02 0.81 0.192 1.0
hardship_doctor      0.88 0.13 0.71 0.290 1.0

                       RC1  RC2
SS loadings           2.81 1.06
Proportion Var        0.56 0.21
Cumulative Var        0.56 0.77
Proportion Explained  0.73 0.27
Cumulative Proportion 0.73 1.00

 With component correlations of 
      RC1   RC2
RC1  1.00 -0.34
RC2 -0.34  1.00

Mean item complexity =  1
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.09 
 with the empirical chi square  573  with prob &lt;  1.5e-126 

Fit based upon off diagonal values = 0.97</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="construct-validation.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(pca_results2b,</span>
<span id="cb65-2"><a href="construct-validation.html#cb65-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">&quot;PCA with Financial Variables: Promax Rotation&quot;</span>)</span></code></pre></div>
<p><img src="edpy607_files/figure-html/cons45-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="exercises-1" class="section level4 unnumbered hasAnchor">
<h4>Exercises<a href="construct-validation.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><p>Fit the two-factor CFA model to the data by forcing the correlation between the factors to be zero and compare the model fit to that of the correlated model we estimated earlier using the <code>anova</code> function.</p></li>
<li><p>Use the following model to fit a second-order (i.e., higher-order) model where the pw and nw factors define a higher-order factor of g (i.e., general factor). Note that there is no perfect way to specify a second-order factor when there are only two first-order factors. However, for the sake of our demonstration, we will give it a try and check its model it.</p></li>
</ol>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="construct-validation.html#cb66-1" aria-hidden="true" tabindex="-1"></a>so.model <span class="ot">&lt;-</span> <span class="st">&#39;# Define factors</span></span>
<span id="cb66-2"><a href="construct-validation.html#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="st">             pw =~ fwb1_3 + fwb2_4 + fwb2_1 + fwb1_5 + fwb1_6 + fwb2_3</span></span>
<span id="cb66-3"><a href="construct-validation.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="st">             nw =~ fwb1_2 + fwb1_4 + fwb1_1 + fwb2_2</span></span>
<span id="cb66-4"><a href="construct-validation.html#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="st">             g =~ 1*pw + 1*nw</span></span>
<span id="cb66-5"><a href="construct-validation.html#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="st">             g ~~ g&#39;</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.685326/full">Nieto et al.¬†(2021)</a> show that there is an alternative way to model item wording effects in psychological instruments‚Äìthe random intercept item factor analysis (RIIFA) model. In the RIIFA model introduced by <span class="citation">Maydeu-Olivares &amp; Coffman (<a href="#ref-maydeu2006random" role="doc-biblioref">2006</a>)</span>, the researcher defines a factor associated with all items and an additional ‚Äúwording‚Äù factor. This additional factor is also associated with all items. Its factor loadings are fixed to 1 but its variance is estimated (see Figure 1, Step 3 in <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.685326/full">Nieto et al.¬†(2021)</a>). Fit the RIIFA model to the FWB scale and evaluate the model fit. For this model, you will use the <code>response</code> dataset instead of <code>response_final</code>.</li>
</ol>

</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-R-mirt" class="csl-entry">
Chalmers, P. (2022). <em>Mirt: Multidimensional item response theory</em>. <a href="https://CRAN.R-project.org/package=mirt">https://CRAN.R-project.org/package=mirt</a>
</div>
<div id="ref-condon2014" class="csl-entry">
Condon, D. M., &amp; Revelle, W. (2014). The international cognitive ability resource: Development and initial validation of a public-domain measure. <em>Intelligence</em>, <em>43</em>, 52‚Äì64.
</div>
<div id="ref-R-DataExplorer" class="csl-entry">
Cui, B. (2020). <em>DataExplorer: Automate data exploration and treatment</em>. <a href="http://boxuancui.github.io/DataExplorer/">http://boxuancui.github.io/DataExplorer/</a>
</div>
<div id="ref-hu1999cutoff" class="csl-entry">
Hu, L., &amp; Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>6</em>(1), 1‚Äì55.
</div>
<div id="ref-maydeu2006random" class="csl-entry">
Maydeu-Olivares, A., &amp; Coffman, D. L. (2006). Random intercept item factor analysis. <em>Psychological Methods</em>, <em>11</em>(4), 344.
</div>
<div id="ref-R-psych" class="csl-entry">
Revelle, W. (2022). <em>Psych: Procedures for psychological, psychometric, and personality research</em>. <a href="https://personality-project.org/r/psych/
https://personality-project.org/r/psych-manual.pdf">https://personality-project.org/r/psych/
<div id="ref-revelle2010" class="csl-entry">
Revelle, W., Wilt, J., &amp; Rosenthal, A. (2010). Individual differences in cognition: New methods for examining the personality-cognition link. In <em>Handbook of individual differences in cognition</em> (pp. 27‚Äì49). Springer.
</div>
<div id="ref-R-MASS" class="csl-entry">
Ripley, B. (2022). <em>MASS: Support functions and datasets for venables and ripley‚Äôs MASS</em>. <a href="http://www.stats.ox.ac.uk/pub/MASS4/">http://www.stats.ox.ac.uk/pub/MASS4/</a>
</div>
<div id="ref-R-lavaan" class="csl-entry">
Rosseel, Y., Jorgensen, T. D., &amp; Rockwood, N. (2022). <em>Lavaan: Latent variable analysis</em>. <a href="https://lavaan.ugent.be">https://lavaan.ugent.be</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="advanced-irt-applications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/okanbulut/edpy607/tree/master/01-construct.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["edpy607.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
